{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SYNTAX FOR praw instance\n",
    "\n",
    "reddit = praw.Reddit(client_id='CLIENT_ID',\n",
    "                     client_secret=\"CLIENT_SECRET\", password='PASSWORD',\n",
    "                     user_agent='USERAGENT', username='USERNAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALISING PRAW INSTANCES\n",
    "# AS WELL AS CREATE AN OBJECT FOR THE SUBREDDIT\n",
    "redditObj = praw.Reddit(client_id='bDeE8HyIL4WqVw',\n",
    "                        client_secret='R0X7ghLgpVwIjTyGdJPgJwF5rG4',\n",
    "                        user_agent='reddit-flair-detector',\n",
    "                        username='culifer_time')\n",
    "\n",
    "subredditObj = redditObj.subreddit('india')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<praw.reddit.Reddit object at 0x7f945d744b50>\n",
      "india\n"
     ]
    }
   ],
   "source": [
    "print(redditObj)\n",
    "print(subredditObj)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "reddit = praw.Reddit(client_id='#', client_secret='#', user_agent='#', username='#', password='#')\n",
    "\n",
    "subreddit = reddit.subreddit('india')\n",
    "topics_dict = {\"flair\":[], \"title\":[], \"score\":[], \"id\":[], \"url\":[], \"comms_num\": [], \"created\": [], \"body\":[], \"author\":[], \"comments\":[]}\n",
    "\n",
    "for flair in flairs:\n",
    "  \n",
    "  get_subreddits = subreddit.search(flair, limit=100)\n",
    "  \n",
    "  for submission in get_subreddits:\n",
    "    \n",
    "    topics_dict[\"flair\"].append(flair)\n",
    "    topics_dict[\"title\"].append(submission.title)\n",
    "    topics_dict[\"score\"].append(submission.score)\n",
    "    topics_dict[\"id\"].append(submission.id)\n",
    "    topics_dict[\"url\"].append(submission.url)\n",
    "    topics_dict[\"comms_num\"].append(submission.num_comments)\n",
    "    topics_dict[\"created\"].append(submission.created)\n",
    "    topics_dict[\"body\"].append(submission.selftext)\n",
    "    topics_dict[\"author\"].append(submission.author)\n",
    "    \n",
    "    submission.comments.replace_more(limit=None)\n",
    "    comment = ''\n",
    "    for top_level_comment in submission.comments:\n",
    "      comment = comment + ' ' + top_level_comment.body\n",
    "    topics_dict[\"comments\"].append(comment)\n",
    "    \n",
    "topics_data = pd.DataFrame(topics_dict)\n",
    "_timestamp = topics_data[\"created\"].apply(get_date)\n",
    "topics_data = topics_data.assign(timestamp = _timestamp)\n",
    "del topics_data['created']\n",
    "topics_data.to_csv('reddit-india-data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>flair</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>comments</th>\n",
       "      <th>permalink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, author, flair, title, body, comments, permalink]\n",
       "Index: []"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CREATE AN EMPTY DATAFRAME WHICH WILL STORE THE POSTS AT A LATER TIME\n",
    "df = pd.DataFrame(columns=[\"id\", \"author\", \"flair\", \"title\", \"body\", \"comments\", \"permalink\"])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sports',\n",
       " 'Politics',\n",
       " 'AskIndia',\n",
       " 'Business/Finance',\n",
       " 'Food',\n",
       " 'Science/Technology',\n",
       " 'Non-Political',\n",
       " 'Photography',\n",
       " 'Policy/Economy',\n",
       " 'Scheduled',\n",
       " '[R]eddiquette']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# USING PRAW TO GET ATLEAST 1000 POSTS PER FLAIR\n",
    "# FLAIRS ARE DEFINED BEFOREHAND\n",
    "flairs = [\"Sports\", \"Politics\", \"AskIndia\", \"Business/Finance\", \"Food\", \"Science/Technology\", \"Non-Political\", \"Photography\", \"Policy/Economy\", \"Scheduled\", \"[R]eddiquette\"]\n",
    "\n",
    "flairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AN EMPTY ARRAY TO STORE ALL THE POSTS\n",
    "posts = []\n",
    "\n",
    "# WE WON'T DIRECTLY ADD DATA ROW-BY-ROW TO 'df' SINCE IT IS HIGHLY INEFFICIENT\n",
    "# WE'LL LATER CONVERT 'posts' TO DATAFRAME\n",
    "\n",
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<praw.models.listing.generator.ListingGenerator object at 0x7f9459003250>\n",
      "Sports\n",
      "<praw.models.listing.generator.ListingGenerator object at 0x7f9459003e90>\n",
      "Politics\n",
      "<praw.models.listing.generator.ListingGenerator object at 0x7f9453f94310>\n",
      "AskIndia\n",
      "<praw.models.listing.generator.ListingGenerator object at 0x7f94590036d0>\n",
      "Business/Finance\n",
      "<praw.models.listing.generator.ListingGenerator object at 0x7f9459003cd0>\n",
      "Food\n",
      "<praw.models.listing.generator.ListingGenerator object at 0x7f945ba77f10>\n",
      "Science/Technology\n",
      "<praw.models.listing.generator.ListingGenerator object at 0x7f9453f94e90>\n",
      "Non-Political\n",
      "<praw.models.listing.generator.ListingGenerator object at 0x7f9453f94b10>\n",
      "Photography\n",
      "<praw.models.listing.generator.ListingGenerator object at 0x7f9458d4f150>\n",
      "Policy/Economy\n",
      "<praw.models.listing.generator.ListingGenerator object at 0x7f9459003510>\n",
      "Scheduled\n",
      "<praw.models.listing.generator.ListingGenerator object at 0x7f9459003c10>\n",
      "[R]eddiquette\n"
     ]
    }
   ],
   "source": [
    "# CHECKING IF THE PRAW OBJECTS ARE FUNCTIONING \n",
    "for flair in flairs:\n",
    "    flair_posts = subredditObj.search(flair, syntax='lucene')\n",
    "    \n",
    "    print(flair_posts)\n",
    "    print(flair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "for flair in flairs:\n",
    "    flair_posts = subredditObj.search(flair, syntax='lucene',limit=None)\n",
    "    \n",
    "    for post in subredditObj.search(str(flair), syntax='lucene'):\n",
    "        \n",
    "        # GET EMPTY VARIABLE TO STORE THE COMMENTS\n",
    "        comments =  ''\n",
    "        post.comments.replace_more(limit=0)\n",
    "        max_comment = 50 # CAN BE SET/CHANGED MANUALLY\n",
    "        i = 0\n",
    "        for comment in post.comments.list():\n",
    "            comments = comment.body + \" \"\n",
    "            i = i+1\n",
    "            if(i > max_comment):\n",
    "                break\n",
    "        \n",
    "        posts.append([post.id, post.author, flair, post.title, post.selftext, comments, post.permalink])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['fqgrjr',\n",
       "  Redditor(name='legithousefly'),\n",
       "  'Sports',\n",
       "  'My schoolâ€™s 1980ish sports day score board',\n",
       "  '',\n",
       "  'Well when i was studying there i heard it from other students these reasons and how all 4 are parsi ',\n",
       "  '/r/india/comments/fqgrjr/my_schools_1980ish_sports_day_score_board/']]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>flair</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>comments</th>\n",
       "      <th>permalink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fqgrjr</td>\n",
       "      <td>legithousefly</td>\n",
       "      <td>Sports</td>\n",
       "      <td>My schoolâ€™s 1980ish sports day score board</td>\n",
       "      <td></td>\n",
       "      <td>Well when i was studying there i heard it from...</td>\n",
       "      <td>/r/india/comments/fqgrjr/my_schools_1980ish_sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fhvl03</td>\n",
       "      <td>hipporama</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Delhi Deputy Chief Minister Manish Sisodia: We...</td>\n",
       "      <td></td>\n",
       "      <td>The players would still be at risk though.</td>\n",
       "      <td>/r/india/comments/fhvl03/delhi_deputy_chief_mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fl5tj6</td>\n",
       "      <td>d2a2d2a</td>\n",
       "      <td>Sports</td>\n",
       "      <td>What is a sport every Indian born before 1990 ...</td>\n",
       "      <td>One of the only team sports which can be playe...</td>\n",
       "      <td>We played this as kids too! But I donâ€™t think ...</td>\n",
       "      <td>/r/india/comments/fl5tj6/what_is_a_sport_every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exk8n6</td>\n",
       "      <td>hipporama</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Govt cuts National Sports Federations &amp; SAI bu...</td>\n",
       "      <td></td>\n",
       "      <td>4D chess right there...</td>\n",
       "      <td>/r/india/comments/exk8n6/govt_cuts_national_sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fhb1v6</td>\n",
       "      <td>wildergears</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Is snowboarding as a sport emerging trend in I...</td>\n",
       "      <td>Just like camping/hiking has boomed this decad...</td>\n",
       "      <td>But recent events like khelo india 2020 - Wint...</td>\n",
       "      <td>/r/india/comments/fhb1v6/is_snowboarding_as_a_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id         author   flair  \\\n",
       "0  fqgrjr  legithousefly  Sports   \n",
       "1  fhvl03      hipporama  Sports   \n",
       "2  fl5tj6        d2a2d2a  Sports   \n",
       "3  exk8n6      hipporama  Sports   \n",
       "4  fhb1v6    wildergears  Sports   \n",
       "\n",
       "                                               title  \\\n",
       "0         My schoolâ€™s 1980ish sports day score board   \n",
       "1  Delhi Deputy Chief Minister Manish Sisodia: We...   \n",
       "2  What is a sport every Indian born before 1990 ...   \n",
       "3  Govt cuts National Sports Federations & SAI bu...   \n",
       "4  Is snowboarding as a sport emerging trend in I...   \n",
       "\n",
       "                                                body  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2  One of the only team sports which can be playe...   \n",
       "3                                                      \n",
       "4  Just like camping/hiking has boomed this decad...   \n",
       "\n",
       "                                            comments  \\\n",
       "0  Well when i was studying there i heard it from...   \n",
       "1        The players would still be at risk though.    \n",
       "2  We played this as kids too! But I donâ€™t think ...   \n",
       "3                           4D chess right there...    \n",
       "4  But recent events like khelo india 2020 - Wint...   \n",
       "\n",
       "                                           permalink  \n",
       "0  /r/india/comments/fqgrjr/my_schools_1980ish_sp...  \n",
       "1  /r/india/comments/fhvl03/delhi_deputy_chief_mi...  \n",
       "2  /r/india/comments/fl5tj6/what_is_a_sport_every...  \n",
       "3  /r/india/comments/exk8n6/govt_cuts_national_sp...  \n",
       "4  /r/india/comments/fhb1v6/is_snowboarding_as_a_...  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(posts,columns=[\"id\", \"author\", \"flair\", \"title\", \"body\", \"comments\", \"permalink\"])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           object\n",
       "author       object\n",
       "flair        object\n",
       "title        object\n",
       "body         object\n",
       "comments     object\n",
       "permalink    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           1018\n",
       "author       1018\n",
       "flair        1018\n",
       "title        1018\n",
       "body         1018\n",
       "comments     1018\n",
       "permalink    1018\n",
       "dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"flair\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DISTRIBUTION OF FLAIRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sports\n",
      "100\n",
      "Politics\n",
      "100\n",
      "AskIndia\n",
      "100\n",
      "Business/Finance\n",
      "100\n",
      "Food\n",
      "100\n",
      "Science/Technology\n",
      "100\n",
      "Non-Political\n",
      "100\n",
      "Photography\n",
      "100\n",
      "Policy/Economy\n",
      "100\n",
      "Scheduled\n",
      "100\n",
      "[R]eddiquette\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "for flair in flairs:\n",
    "    print(flair)\n",
    "    print(len(df[df[\"flair\"] == flair]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "996"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"permalink\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT THE DATA TO A .CSV FILE\n",
    "df.to_csv(r'../data/reddit_data_raw_primary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

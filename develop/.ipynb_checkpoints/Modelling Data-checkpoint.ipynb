{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, matthews_corrcoef\n",
    "from math            import sqrt\n",
    "from sklearn.metrics import confusion_matrix, r2_score\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>flair</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>processed_url</th>\n",
       "      <th>body-empty</th>\n",
       "      <th>comments-empty</th>\n",
       "      <th>body_comments_combined</th>\n",
       "      <th>lemmatized_body_comments</th>\n",
       "      <th>lemmatized_title</th>\n",
       "      <th>lemmatized_body_only</th>\n",
       "      <th>lemmatized_comments_only</th>\n",
       "      <th>lemmatized_all_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fqgrjr</td>\n",
       "      <td>legithousefly</td>\n",
       "      <td>Sports</td>\n",
       "      <td>My school’s 1980ish sports day score board</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Well when i was studying there i heard it from...</td>\n",
       "      <td>/r/india/comments/fqgrjr/my_schools_1980ish_sp...</td>\n",
       "      <td>my schools 1980ish sports day score board</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Well when i was studying there i heard it from...</td>\n",
       "      <td>Well when i wa studying there i heard it from ...</td>\n",
       "      <td>My school s 1980ish sport day score board</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Well when i wa studying there i heard it from ...</td>\n",
       "      <td>My school s 1980ish sport day score boardWell ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fhvl03</td>\n",
       "      <td>hipporama</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Delhi Deputy Chief Minister Manish Sisodia: We...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The players would still be at risk though.</td>\n",
       "      <td>/r/india/comments/fhvl03/delhi_deputy_chief_mi...</td>\n",
       "      <td>delhi deputy chief minister manish sisodia we</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>The players would still be at risk though.</td>\n",
       "      <td>The player would still be at risk though</td>\n",
       "      <td>Delhi Deputy Chief Minister Manish Sisodia We ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The player would still be at risk though</td>\n",
       "      <td>Delhi Deputy Chief Minister Manish Sisodia We ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fl5tj6</td>\n",
       "      <td>d2a2d2a</td>\n",
       "      <td>Sports</td>\n",
       "      <td>What is a sport every Indian born before 1990 ...</td>\n",
       "      <td>One of the only team sports which can be playe...</td>\n",
       "      <td>We played this as kids too! But I don’t think ...</td>\n",
       "      <td>/r/india/comments/fl5tj6/what_is_a_sport_every...</td>\n",
       "      <td>what is a sport every indian born before 1990</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>One of the only team sports which can be playe...</td>\n",
       "      <td>One of the only team sport which can be played...</td>\n",
       "      <td>What is a sport every Indian born before 1990 ...</td>\n",
       "      <td>One of the only team sport which can be played...</td>\n",
       "      <td>We played this a kid too But I don t think I e...</td>\n",
       "      <td>What is a sport every Indian born before 1990 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>exk8n6</td>\n",
       "      <td>hipporama</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Govt cuts National Sports Federations &amp; SAI bu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4D chess right there...</td>\n",
       "      <td>/r/india/comments/exk8n6/govt_cuts_national_sp...</td>\n",
       "      <td>govt cuts national sports federations sai budget</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4D chess right there...</td>\n",
       "      <td>4D chess right there</td>\n",
       "      <td>Govt cut National Sports Federations SAI budge...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4D chess right there</td>\n",
       "      <td>Govt cut National Sports Federations SAI budge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fhb1v6</td>\n",
       "      <td>wildergears</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Is snowboarding as a sport emerging trend in I...</td>\n",
       "      <td>Just like camping/hiking has boomed this decad...</td>\n",
       "      <td>But recent events like khelo india 2020 - Wint...</td>\n",
       "      <td>/r/india/comments/fhb1v6/is_snowboarding_as_a_...</td>\n",
       "      <td>is snowboarding as a sport emerging trend in i...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Just like camping/hiking has boomed this decad...</td>\n",
       "      <td>Just like camping hiking ha boomed this decade...</td>\n",
       "      <td>Is snowboarding a a sport emerging trend in India</td>\n",
       "      <td>Just like camping hiking ha boomed this decade...</td>\n",
       "      <td>But recent event like khelo india 2020 Winter ...</td>\n",
       "      <td>Is snowboarding a a sport emerging trend in In...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id         author   flair  \\\n",
       "0  fqgrjr  legithousefly  Sports   \n",
       "1  fhvl03      hipporama  Sports   \n",
       "2  fl5tj6        d2a2d2a  Sports   \n",
       "3  exk8n6      hipporama  Sports   \n",
       "4  fhb1v6    wildergears  Sports   \n",
       "\n",
       "                                               title  \\\n",
       "0         My school’s 1980ish sports day score board   \n",
       "1  Delhi Deputy Chief Minister Manish Sisodia: We...   \n",
       "2  What is a sport every Indian born before 1990 ...   \n",
       "3  Govt cuts National Sports Federations & SAI bu...   \n",
       "4  Is snowboarding as a sport emerging trend in I...   \n",
       "\n",
       "                                                body  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  One of the only team sports which can be playe...   \n",
       "3                                                NaN   \n",
       "4  Just like camping/hiking has boomed this decad...   \n",
       "\n",
       "                                            comments  \\\n",
       "0  Well when i was studying there i heard it from...   \n",
       "1        The players would still be at risk though.    \n",
       "2  We played this as kids too! But I don’t think ...   \n",
       "3                           4D chess right there...    \n",
       "4  But recent events like khelo india 2020 - Wint...   \n",
       "\n",
       "                                           permalink  \\\n",
       "0  /r/india/comments/fqgrjr/my_schools_1980ish_sp...   \n",
       "1  /r/india/comments/fhvl03/delhi_deputy_chief_mi...   \n",
       "2  /r/india/comments/fl5tj6/what_is_a_sport_every...   \n",
       "3  /r/india/comments/exk8n6/govt_cuts_national_sp...   \n",
       "4  /r/india/comments/fhb1v6/is_snowboarding_as_a_...   \n",
       "\n",
       "                                       processed_url  body-empty  \\\n",
       "0          my schools 1980ish sports day score board        True   \n",
       "1      delhi deputy chief minister manish sisodia we        True   \n",
       "2      what is a sport every indian born before 1990       False   \n",
       "3   govt cuts national sports federations sai budget        True   \n",
       "4  is snowboarding as a sport emerging trend in i...       False   \n",
       "\n",
       "   comments-empty                             body_comments_combined  \\\n",
       "0           False  Well when i was studying there i heard it from...   \n",
       "1           False       The players would still be at risk though.     \n",
       "2           False  One of the only team sports which can be playe...   \n",
       "3           False                          4D chess right there...     \n",
       "4           False  Just like camping/hiking has boomed this decad...   \n",
       "\n",
       "                            lemmatized_body_comments  \\\n",
       "0  Well when i wa studying there i heard it from ...   \n",
       "1           The player would still be at risk though   \n",
       "2  One of the only team sport which can be played...   \n",
       "3                               4D chess right there   \n",
       "4  Just like camping hiking ha boomed this decade...   \n",
       "\n",
       "                                    lemmatized_title  \\\n",
       "0          My school s 1980ish sport day score board   \n",
       "1  Delhi Deputy Chief Minister Manish Sisodia We ...   \n",
       "2  What is a sport every Indian born before 1990 ...   \n",
       "3  Govt cut National Sports Federations SAI budge...   \n",
       "4  Is snowboarding a a sport emerging trend in India   \n",
       "\n",
       "                                lemmatized_body_only  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  One of the only team sport which can be played...   \n",
       "3                                                NaN   \n",
       "4  Just like camping hiking ha boomed this decade...   \n",
       "\n",
       "                            lemmatized_comments_only  \\\n",
       "0  Well when i wa studying there i heard it from ...   \n",
       "1           The player would still be at risk though   \n",
       "2  We played this a kid too But I don t think I e...   \n",
       "3                               4D chess right there   \n",
       "4  But recent event like khelo india 2020 Winter ...   \n",
       "\n",
       "                               lemmatized_all_params  \n",
       "0  My school s 1980ish sport day score boardWell ...  \n",
       "1  Delhi Deputy Chief Minister Manish Sisodia We ...  \n",
       "2  What is a sport every Indian born before 1990 ...  \n",
       "3  Govt cut National Sports Federations SAI budge...  \n",
       "4  Is snowboarding a a sport emerging trend in In...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/reddit_data_preprocessed.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                          object\n",
       "author                      object\n",
       "flair                       object\n",
       "title                       object\n",
       "body                        object\n",
       "comments                    object\n",
       "permalink                   object\n",
       "processed_url               object\n",
       "body-empty                    bool\n",
       "comments-empty                bool\n",
       "body_comments_combined      object\n",
       "lemmatized_body_comments    object\n",
       "lemmatized_title            object\n",
       "lemmatized_body_only        object\n",
       "lemmatized_comments_only    object\n",
       "lemmatized_all_params       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple NaN removal before running the models\n",
    "df = df.replace(np.nan, \"\", regex=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUNNING MODELS\n",
    "\n",
    "We will start off by choosing the params in the following order:\n",
    "1. Body\n",
    "2. Comments\n",
    "3. Title\n",
    "4. URL (permalink)\n",
    "5. Body + Comments\n",
    "6. Body + Comments + Title + URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_X = {\n",
    "    \"body\": df[\"lemmatized_body_only\"],\n",
    "    \"comments\": df[\"lemmatized_comments_only\"], \n",
    "     \"title\": df[\"lemmatized_title\"],\n",
    "    \"URL\": df[\"processed_url\"],\n",
    "    \"body + comments\": df[\"lemmatized_body_comments\"],\n",
    "    \"All Params\": df[\"lemmatized_all_params\"] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = choice_X[\"All Params\"]\n",
    "y = df[\"flair\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define a function to model the data as per the parameters chosen by us\n",
    "# Stratify param is used to match the distribution of the flairs\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'penalty'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9573c7adc0a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m                           \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcvec_pipe_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                           \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                           penalty='l1')\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Model Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'penalty'"
     ]
    }
   ],
   "source": [
    "# Pipeline initiate\n",
    "cvec_lr_pipe = Pipeline([(\"cvec\", CountVectorizer()),\n",
    "                         (\"log_reg\", LogisticRegression())])\n",
    "\n",
    "# Hyperparameters setup\n",
    "cvec_pipe_params = {\n",
    "    \"cvec__max_features\": [125],\n",
    "    \"cvec__ngram_range\": [(1,2)],\n",
    "    \"cvec__stop_words\" : [None]\n",
    "}\n",
    "\n",
    "# Grid Search Object\n",
    "cvec_lr_gs = GridSearchCV(cvec_lr_pipe,\n",
    "                          param_grid=cvec_pipe_params,\n",
    "                          cv=5)\n",
    "\n",
    "# Model Fit\n",
    "cvec_lr_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec_lr_train_preds = cvec_lr_gs.predict(X_train)\n",
    "\n",
    "cvec_lr_preds = cvec_lr_gs.predict(X_test)\n",
    "\n",
    "cvec_lr_probs = cvec_lr_gs.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6841415465268676"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, cvec_lr_train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, cvec_lr_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using TFIDF VECTORIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tvec',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_acce...\n",
       "                                                           max_iter=100,\n",
       "                                                           multi_class='auto',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'tvec__max_features': [650],\n",
       "                         'tvec__ngram_range': [(1, 1)],\n",
       "                         'tvec__stop_words': [None]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline\n",
    "tvec_lr_pipe = Pipeline([(\"tvec\", TfidfVectorizer()), \n",
    "                         (\"log_reg\", LogisticRegression())])\n",
    "\n",
    "tvec_pipe_params = {\n",
    "    \"tvec__max_features\": [650], \n",
    "    \"tvec__ngram_range\" : [(1,1)], \n",
    "    \"tvec__stop_words\"  : [None]\n",
    "}\n",
    "\n",
    "tvec_lr_gs = GridSearchCV(tvec_lr_pipe,\n",
    "                          param_grid=tvec_pipe_params, \n",
    "                          cv = 5)\n",
    "\n",
    "tvec_lr_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec_lr_train_preds = tvec_lr_gs.predict(X_train)\n",
    "\n",
    "tvec_lr_preds       = tvec_lr_gs.predict(X_test) \n",
    "\n",
    "tvec_lr_probas     = tvec_lr_gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9017038007863696"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, tvec_lr_train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6823529411764706"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, tvec_lr_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING FUNCTIONS FOR EACH OF THE MODEL PRESENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USING COUNT VECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION FOR CVEC LR\n",
    "def cvec_Logistic(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify = y)\n",
    "    # Pipeline initiate\n",
    "    cvec_lr_pipe = Pipeline([(\"cvec\", CountVectorizer()),\n",
    "                             (\"log_reg\", LogisticRegression())])\n",
    "\n",
    "    # Hyperparameters setup\n",
    "    cvec_pipe_params = {\n",
    "        \"cvec__max_features\": [125],\n",
    "        \"cvec__ngram_range\": [(1,2)],\n",
    "        \"cvec__stop_words\" : [None]\n",
    "    }\n",
    "\n",
    "    # Grid Search Object\n",
    "    cvec_lr_gs = GridSearchCV(cvec_lr_pipe,\n",
    "                              param_grid=cvec_pipe_params,\n",
    "                              cv=5)\n",
    "\n",
    "    # Model Fit\n",
    "    cvec_lr_gs.fit(X_train, y_train)\n",
    "    \n",
    "    cvec_lr_train_preds = cvec_lr_gs.predict(X_train)\n",
    "    cvec_lr_preds = cvec_lr_gs.predict(X_test)\n",
    "    cvec_lr_probs = cvec_lr_gs.predict_proba(X_test)\n",
    "    \n",
    "    print(\"Train Accuracy\")\n",
    "    print(accuracy_score(y_train, cvec_lr_train_preds))\n",
    "    print(\"Test Accuracy\")\n",
    "    print(accuracy_score(y_test, cvec_lr_preds))\n",
    "    \n",
    "    print(confusion_matrix(y_test, cvec_lr_preds))\n",
    "    \n",
    "    return accuracy_score(y_train, cvec_lr_train_preds), accuracy_score(y_test, cvec_lr_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USING TFIDR VECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION FOR TVEC LR\n",
    "def tvec_Logistic(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify = y)\n",
    "    # Pipeline\n",
    "    tvec_lr_pipe = Pipeline([(\"tvec\", TfidfVectorizer()), \n",
    "                             (\"log_reg\", LogisticRegression())])\n",
    "\n",
    "    tvec_pipe_params = {\n",
    "        \"tvec__max_features\": [650], \n",
    "        \"tvec__ngram_range\" : [(1,1)], \n",
    "        \"tvec__stop_words\"  : [None]\n",
    "    }\n",
    "\n",
    "    tvec_lr_gs = GridSearchCV(tvec_lr_pipe,\n",
    "                              param_grid=tvec_pipe_params, \n",
    "                              cv = 5)\n",
    "\n",
    "    tvec_lr_gs.fit(X_train, y_train)\n",
    "    \n",
    "    tvec_lr_train_preds = tvec_lr_gs.predict(X_train)\n",
    "    tvec_lr_preds       = tvec_lr_gs.predict(X_test) \n",
    "    tvec_lr_probas     = tvec_lr_gs.predict(X_test)\n",
    "    \n",
    "    print(\"Train Accuracy\")\n",
    "    print(accuracy_score(y_train, tvec_lr_train_preds))\n",
    "    print(\"Test Accuracy\")\n",
    "    print(accuracy_score(y_test, tvec_lr_preds))\n",
    "    \n",
    "    print (confusion_matrix(y_test, tvec_lr_preds))\n",
    "    \n",
    "    return accuracy_score(y_train, tvec_lr_train_preds), accuracy_score(y_test, tvec_lr_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPPORT VECTOR CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvec_SVC(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify = y)\n",
    "    \n",
    "    cvec_svc_pipe = Pipeline([\n",
    "        (\"cvec\", CountVectorizer()),\n",
    "        (\"svc\", SVC())\n",
    "    ])\n",
    "    \n",
    "    cvec_pipe_params = {\n",
    "        \"cvec__max_features\": [319], \n",
    "        \"cvec__ngram_range\" : [(1,2)], \n",
    "        \"cvec__stop_words\"  : [None],\n",
    "        \"svc__C\"            : [1.0],\n",
    "        \"svc__kernel\"       : [\"rbf\"],\n",
    "        \"svc__gamma\"        : [\"auto\"]\n",
    "    }\n",
    "    \n",
    "    cvec_svc_gs = GridSearchCV(\n",
    "        cvec_svc_pipe, \n",
    "        param_grid = cvec_pipe_params, \n",
    "        cv         = 5\n",
    "    )\n",
    "    \n",
    "    cvec_svc_gs.fit(X_train, y_train)\n",
    "    \n",
    "    cvec_svc_train_preds = cvec_svc_gs.predict(X_train)\n",
    "    cvec_svc_preds       = cvec_svc_gs.predict(X_test)\n",
    "    \n",
    "    print(\"Train Accuracy\")\n",
    "    print(accuracy_score(y_train, cvec_svc_train_preds))\n",
    "    print(\"Test Accuracy\")\n",
    "    print(accuracy_score(y_test, cvec_svc_preds))\n",
    "    \n",
    "    print(confusion_matrix(y_test, cvec_svc_preds))\n",
    "    \n",
    "    return accuracy_score(y_train, cvec_svc_train_preds), accuracy_score(y_test, cvec_svc_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using TFID Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvec_SVC(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify = y)\n",
    "    \n",
    "    # Setup pipeline\n",
    "    tvec_svc_pipe = Pipeline([\n",
    "        (\"tvec\", TfidfVectorizer()), \n",
    "        (\"svc\", SVC())\n",
    "    ])\n",
    "\n",
    "    # Setting hyperparameters\n",
    "    tvec_pipe_params = {\"tvec__max_features\": [1], \n",
    "                        \"tvec__ngram_range\" : [(1,1)], \n",
    "                        \"tvec__stop_words\"  : [None],\n",
    "                        \"svc__C\"            : [1.0],\n",
    "                        \"svc__kernel\"       : [\"rbf\"],\n",
    "                        \"svc__gamma\"        : [\"auto\"]}\n",
    "\n",
    "    tvec_svc_gs = GridSearchCV(tvec_svc_pipe, \n",
    "                               param_grid = tvec_pipe_params, \n",
    "                               cv         = 5)\n",
    "\n",
    "    # Fitting the model \n",
    "    tvec_svc_gs.fit(X_train, y_train);\n",
    "    tvec_svc_train_preds = tvec_svc_gs.predict(X_train)\n",
    "    tvec_svc_preds       = tvec_svc_gs.predict(X_test)\n",
    "    \n",
    "    print(\"Train Accuracy\")\n",
    "    print(accuracy_score(y_train, tvec_svc_train_preds))\n",
    "    print(\"Test Accuracy\")\n",
    "    print(accuracy_score(y_test, tvec_svc_preds))\n",
    "    \n",
    "    print(confusion_matrix(y_test, tvec_svc_preds))\n",
    "    \n",
    "    return accuracy_score(y_train, tvec_svc_train_preds), accuracy_score(y_test, tvec_svc_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST CLASSIFIER "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using Count Vectoriser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvec_RF(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify = y)\n",
    "    # Creating the pipeline\n",
    "\n",
    "    cvec_rf_pipe = Pipeline([(\"cvec\", CountVectorizer()), \n",
    "                             (\"rf\", RandomForestClassifier(random_state = 42))])\n",
    "\n",
    "    # Setting hyperparameters\n",
    "    cvec_pipe_params = {\"cvec__max_features\"   : [1000], \n",
    "                        \"cvec__ngram_range\"    : [(1,1)], \n",
    "                        \"cvec__stop_words\"     : [None],\n",
    "                        \"rf__n_estimators\"     : [72],\n",
    "                        \"rf__min_samples_split\": [6],\n",
    "                        \"rf__min_samples_leaf\" : [2],\n",
    "                        \"rf__max_depth\"        : [20]}\n",
    "\n",
    "    # grid search\n",
    "    cvec_rf_gs = GridSearchCV(cvec_rf_pipe, \n",
    "                              param_grid = cvec_pipe_params, \n",
    "                              cv         = 5,\n",
    "                              n_jobs     = 6)\n",
    "\n",
    "    # Fitting the model to the training data\n",
    "    cvec_rf_gs.fit(X_train, y_train);\n",
    "\n",
    "    # Generating training predictions\n",
    "    cvec_rf_train_preds = cvec_rf_gs.predict(X_train)\n",
    "\n",
    "    # Generating test predictions\n",
    "    cvec_rf_preds       = cvec_rf_gs.predict(X_test) \n",
    "\n",
    "    # Generating test probabilities\n",
    "    cvec_rf_probas      = cvec_rf_gs.predict_proba(X_test)\n",
    "\n",
    "    # Creating the pipeline\n",
    "    cvec_rf_pipe = Pipeline([(\"cvec\", CountVectorizer()), \n",
    "                             (\"rf\", RandomForestClassifier(random_state = 42))])\n",
    "\n",
    "    # Setting CVEC and pipeline hyperparameters\n",
    "    cvec_pipe_params = {\"cvec__max_features\"   : [1000], \n",
    "                        \"cvec__ngram_range\"    : [(1,1)], \n",
    "                        \"cvec__stop_words\"     : [None],\n",
    "                        \"rf__n_estimators\"     : [72],\n",
    "                        \"rf__min_samples_split\": [6],\n",
    "                        \"rf__min_samples_leaf\" : [2],\n",
    "                        \"rf__max_depth\"        : [20]}\n",
    "\n",
    "    # Instantiating the grid search\n",
    "    cvec_rf_gs = GridSearchCV(cvec_rf_pipe, \n",
    "                              param_grid = cvec_pipe_params, \n",
    "                              cv         = 5,\n",
    "                              n_jobs     = 6)\n",
    "\n",
    "    # Fitting the model to the training data\n",
    "    cvec_rf_gs.fit(X_train, y_train);\n",
    "\n",
    "    # Generating training predictions\n",
    "    cvec_rf_train_preds = cvec_rf_gs.predict(X_train)\n",
    "    # Generating test predictions\n",
    "    cvec_rf_preds       = cvec_rf_gs.predict(X_test) \n",
    "    # Generating test probabilities\n",
    "    cvec_rf_probas      = cvec_rf_gs.predict_proba(X_test)\n",
    "    \n",
    "    print(\"Train Accuracy\")\n",
    "    print(accuracy_score(y_train, cvec_rf_train_preds))\n",
    "    print(\"Test Accuracy\")\n",
    "    print(accuracy_score(y_test, cvec_rf_preds))\n",
    "    \n",
    "    print(confusion_matrix(y_test, cvec_rf_preds))\n",
    "    \n",
    "    return accuracy_score(y_train, cvec_rf_train_preds), accuracy_score(y_test, cvec_rf_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvec_RF(X,y):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify = y)\n",
    "        # Creating the pipeline\n",
    "\n",
    "    tvec_rf_pipe = Pipeline([(\"tvec\", TfidfVectorizer()), \n",
    "                             (\"rf\", RandomForestClassifier(random_state = 42))])\n",
    "\n",
    "    # Setting the TVEC and pipeline hyperparameters\n",
    "\n",
    "    tvec_pipe_params = {\"tvec__max_features\"   : [250], \n",
    "                        \"tvec__ngram_range\"    : [(1,2)], \n",
    "                        \"tvec__stop_words\"     : [None],\n",
    "                        \"rf__n_estimators\"     : [30],\n",
    "                        \"rf__min_samples_split\": [6],\n",
    "                        \"rf__min_samples_leaf\" : [2],\n",
    "                        \"rf__max_depth\"        : [12]}\n",
    "\n",
    "    # Instantiating the grid search\n",
    "\n",
    "    tvec_rf_gs = GridSearchCV(tvec_rf_pipe, \n",
    "                              param_grid = tvec_pipe_params, \n",
    "                              cv         = 5,\n",
    "                              n_jobs     = 6)\n",
    "\n",
    "    # Fitting the model to the testing data\n",
    "\n",
    "    tvec_rf_gs.fit(X_train, y_train);\n",
    "\n",
    "    # Generating training predictions\n",
    "\n",
    "    tvec_rf_train_preds = tvec_rf_gs.predict(X_train)\n",
    "\n",
    "    # Generating test predictions\n",
    "\n",
    "    tvec_rf_preds       = tvec_rf_gs.predict(X_test) \n",
    "\n",
    "    # Generating test probabilities\n",
    "\n",
    "    tvec_rf_probas      = tvec_rf_gs.predict_proba(X_test)\n",
    "\n",
    "    print(\"Train Accuracy\")\n",
    "    print(accuracy_score(y_train, tvec_rf_train_preds))\n",
    "    print(\"Test Accuracy\")\n",
    "    print(accuracy_score(y_test, tvec_rf_preds))\n",
    "    \n",
    "    print(confusion_matrix(y_test, tvec_rf_preds))\n",
    "    \n",
    "    return accuracy_score(y_train, tvec_rf_train_preds), accuracy_score(y_test, tvec_rf_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUNNING ACCURACY TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When Considering body\n",
      "\n",
      "\n",
      "USING COUNT VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.49934469200524245\n",
      "Test Accuracy\n",
      "0.2235294117647059\n",
      "[[ 3  4  1  2  1  0  1  4  6  3  0]\n",
      " [ 1 10  5  1  0  3  0  3  2  0  0]\n",
      " [ 0  2 17  0  0  0  1  5  0  0  0]\n",
      " [ 1  2 14  2  0  0  2  3  0  1  0]\n",
      " [ 1  1 10  1 10  0  0  1  1  0  0]\n",
      " [ 1  6  9  0  0  5  0  1  3  0  0]\n",
      " [ 0  1 17  2  0  1  0  2  1  1  0]\n",
      " [ 3  1 10  1  1  1  1  3  1  2  1]\n",
      " [ 3  2 12  1  0  2  0  1  4  0  0]\n",
      " [ 1  1 10  1  1  1  1  1  5  3  0]\n",
      " [ 0  0  3  0  1  0  0  0  1  0  0]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.3918741808650065\n",
      "Test Accuracy\n",
      "0.23529411764705882\n",
      "[[11  3  9  1  0  1  0  0  0  0  0]\n",
      " [ 4  9  6  1  0  4  0  1  0  0  0]\n",
      " [ 2  0 23  0  0  0  0  0  0  0  0]\n",
      " [ 5  2 18  0  0  0  0  0  0  0  0]\n",
      " [ 3  1 11  0 10  0  0  0  0  0  0]\n",
      " [ 5  4  9  0  0  7  0  0  0  0  0]\n",
      " [ 4  1 18  0  0  2  0  0  0  0  0]\n",
      " [ 6  1 16  0  0  2  0  0  0  0  0]\n",
      " [ 4  6 13  0  0  2  0  0  0  0  0]\n",
      " [ 6  2 15  0  0  2  0  0  0  0  0]\n",
      " [ 1  0  3  0  0  1  0  0  0  0  0]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.6290956749672346\n",
      "Test Accuracy\n",
      "0.42745098039215684\n",
      "[[22  2  0  1  0  0  0  0  0  0  0]\n",
      " [ 0 17  6  0  1  0  0  0  1  0  0]\n",
      " [ 5  0 19  0  0  0  0  1  0  0  0]\n",
      " [ 6  3 14  1  0  0  0  0  0  1  0]\n",
      " [ 1  1 10  1 12  0  0  0  0  0  0]\n",
      " [ 0  3  9  0  0 13  0  0  0  0  0]\n",
      " [ 2  1 17  1  0  2  0  2  0  0  0]\n",
      " [10  0 11  0  1  0  0  3  0  0  0]\n",
      " [ 0  2 12  0  0  1  0  0  9  1  0]\n",
      " [ 1  0 10  0  0  1  0  0  0 13  0]\n",
      " [ 1  0  2  1  0  0  0  0  1  0  0]]\n",
      "\n",
      "\n",
      "USING TFIDF VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.5163826998689384\n",
      "Test Accuracy\n",
      "0.2901960784313726\n",
      "[[13  1  2  1  0  0  1  1  2  4  0]\n",
      " [ 4 11  5  0  1  3  0  1  0  0  0]\n",
      " [ 0  0 21  1  0  0  1  2  0  0  0]\n",
      " [ 4  3 14  0  0  2  0  1  0  1  0]\n",
      " [ 2  1 10  0 10  0  0  2  0  0  0]\n",
      " [ 2  4  9  0  0  9  0  1  0  0  0]\n",
      " [ 2  1 16  1  0  2  0  0  2  1  0]\n",
      " [ 7  3 10  1  1  1  2  0  0  0  0]\n",
      " [ 5  3 12  0  0  4  0  0  1  0  0]\n",
      " [ 1  1 10  0  0  4  0  0  0  9  0]\n",
      " [ 0  1  3  0  0  0  0  0  1  0  0]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.1559633027522936\n",
      "Test Accuracy\n",
      "0.15294117647058825\n",
      "[[18  0  7  0  0  0  0  0  0  0  0]\n",
      " [19  0  6  0  0  0  0  0  0  0  0]\n",
      " [ 4  0 21  0  0  0  0  0  0  0  0]\n",
      " [ 7  0 18  0  0  0  0  0  0  0  0]\n",
      " [13  0 12  0  0  0  0  0  0  0  0]\n",
      " [16  0  9  0  0  0  0  0  0  0  0]\n",
      " [ 8  0 17  0  0  0  0  0  0  0  0]\n",
      " [12  0 13  0  0  0  0  0  0  0  0]\n",
      " [12  0 13  0  0  0  0  0  0  0  0]\n",
      " [14  0 11  0  0  0  0  0  0  0  0]\n",
      " [ 2  0  3  0  0  0  0  0  0  0  0]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.6107470511140236\n",
      "Test Accuracy\n",
      "0.34901960784313724\n",
      "[[17  3  0  1  1  0  0  0  0  3  0]\n",
      " [ 0 13  5  0  2  3  0  0  2  0  0]\n",
      " [ 2  0 22  0  0  0  0  1  0  0  0]\n",
      " [ 3  3 14  1  1  1  0  1  0  1  0]\n",
      " [ 1  1 10  1 10  0  0  2  0  0  0]\n",
      " [ 1  3  9  0  0 12  0  0  0  0  0]\n",
      " [ 3  2 16  0  0  0  1  2  0  1  0]\n",
      " [ 9  1 10  1  2  0  0  2  0  0  0]\n",
      " [ 0  0 12  0  0  2  0  0 11  0  0]\n",
      " [ 7  2 10  1  0  0  0  5  0  0  0]\n",
      " [ 0  0  2  1  0  0  0  1  1  0  0]]\n",
      "When Considering comments\n",
      "\n",
      "\n",
      "USING COUNT VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.5163826998689384\n",
      "Test Accuracy\n",
      "0.1411764705882353\n",
      "[[4 1 2 9 1 1 1 2 0 4 0]\n",
      " [2 2 3 7 3 1 0 3 3 1 0]\n",
      " [1 4 4 3 1 3 2 1 3 3 0]\n",
      " [1 4 1 9 0 1 1 2 0 5 1]\n",
      " [1 1 1 8 4 3 2 1 2 1 1]\n",
      " [1 4 0 6 2 4 3 0 3 2 0]\n",
      " [2 2 2 7 1 4 3 2 1 1 0]\n",
      " [1 4 0 7 1 1 3 2 2 4 0]\n",
      " [1 5 0 8 1 3 2 3 1 1 0]\n",
      " [3 2 4 6 3 1 1 1 2 2 0]\n",
      " [0 0 0 2 0 1 0 0 1 0 1]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.1965923984272608\n",
      "Test Accuracy\n",
      "0.10980392156862745\n",
      "[[ 0  0  0  0 21  0  0  0  1  3  0]\n",
      " [ 2  2  0  0 18  0  0  0  0  3  0]\n",
      " [ 0  1  0  0 18  2  0  0  0  4  0]\n",
      " [ 2  1  0  0 19  0  0  0  0  3  0]\n",
      " [ 1  0  0  0 20  1  0  0  0  3  0]\n",
      " [ 0  2  0  0 16  1  1  2  1  2  0]\n",
      " [ 2  0  0  0 18  0  0  0  0  5  0]\n",
      " [ 1  1  0  0 18  0  1  1  0  3  0]\n",
      " [ 2  2  0  0 17  0  0  0  1  3  0]\n",
      " [ 0  0  0  0 20  0  1  0  1  3  0]\n",
      " [ 0  2  0  0  2  0  0  0  0  1  0]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.6330275229357798\n",
      "Test Accuracy\n",
      "0.17647058823529413\n",
      "[[ 2  1  0  0 10  4  3  0  1  4  0]\n",
      " [ 0  4  0  4  8  5  0  3  1  0  0]\n",
      " [ 3  0  5  2  3  4  4  2  0  2  0]\n",
      " [ 2  2  2  3  8  1  0  2  0  5  0]\n",
      " [ 1  1  1  1 11  5  3  1  0  1  0]\n",
      " [ 1  4  2  0  7  5  3  0  0  3  0]\n",
      " [ 1  1  4  2  5  6  3  1  0  2  0]\n",
      " [ 2  1  4  0  8  2  1  3  1  3  0]\n",
      " [ 3  4  0  3  8  3  1  1  1  1  0]\n",
      " [ 2  1  0  1 10  1  0  3  0  7  0]\n",
      " [ 0  1  0  1  1  0  1  0  0  0  1]]\n",
      "\n",
      "\n",
      "USING TFIDF VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.6854521625163827\n",
      "Test Accuracy\n",
      "0.1568627450980392\n",
      "[[2 4 3 3 6 2 2 2 1 0 0]\n",
      " [3 5 0 0 6 5 2 2 1 1 0]\n",
      " [2 4 5 1 5 4 0 2 1 1 0]\n",
      " [3 1 2 2 8 2 0 0 3 4 0]\n",
      " [2 1 2 0 9 3 3 1 3 1 0]\n",
      " [0 6 2 1 6 4 3 1 1 1 0]\n",
      " [0 3 4 1 5 3 4 1 3 1 0]\n",
      " [3 4 4 2 4 1 2 4 0 1 0]\n",
      " [2 3 0 4 7 1 3 3 1 1 0]\n",
      " [2 3 2 2 7 2 1 1 1 4 0]\n",
      " [0 3 0 1 0 0 1 0 0 0 0]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.11926605504587157\n",
      "Test Accuracy\n",
      "0.10588235294117647\n",
      "[[ 0  7  0  0 18  0  0  0  0  0  0]\n",
      " [ 0 12  0  0 13  0  0  0  0  0  0]\n",
      " [ 0 11  0  0 14  0  0  0  0  0  0]\n",
      " [ 0  8  0  0 17  0  0  0  0  0  0]\n",
      " [ 0 10  0  0 15  0  0  0  0  0  0]\n",
      " [ 0 14  0  0 11  0  0  0  0  0  0]\n",
      " [ 0 11  0  0 14  0  0  0  0  0  0]\n",
      " [ 0  9  0  0 16  0  0  0  0  0  0]\n",
      " [ 0 12  0  0 13  0  0  0  0  0  0]\n",
      " [ 0  8  0  0 17  0  0  0  0  0  0]\n",
      " [ 0  3  0  0  2  0  0  0  0  0  0]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.5111402359108781\n",
      "Test Accuracy\n",
      "0.14901960784313725\n",
      "[[ 1  1  0  7  2  3  3  2  1  5  0]\n",
      " [ 1  3  0 10  2  4  0  2  0  3  0]\n",
      " [ 1  2  5  2  1  4  3  1  0  6  0]\n",
      " [ 1  6  2 11  0  0  2  1  1  1  0]\n",
      " [ 1  2  0  7  2  2  5  3  0  3  0]\n",
      " [ 0  6  1  5  0  5  3  1  0  4  0]\n",
      " [ 1  3  0  8  1  4  5  1  0  2  0]\n",
      " [ 2  4  2  6  2  1  2  2  0  4  0]\n",
      " [ 2  7  1  7  0  4  1  2  1  0  0]\n",
      " [ 3  4  0  7  3  3  1  2  0  2  0]\n",
      " [ 0  1  0  1  0  1  1  0  0  0  1]]\n",
      "When Considering title\n",
      "\n",
      "\n",
      "USING COUNT VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.8217562254259502\n",
      "Test Accuracy\n",
      "0.6627450980392157\n",
      "[[16  3  0  1  0  1  0  2  0  2  0]\n",
      " [ 0 14  0  0  0  6  3  1  0  1  0]\n",
      " [ 0  0 23  0  1  0  0  1  0  0  0]\n",
      " [ 0  0  0 25  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0 21  1  0  1  0  0  0]\n",
      " [ 2  4  0  0  0 14  0  3  1  1  0]\n",
      " [ 0  1  1  1  0  3 17  0  2  0  0]\n",
      " [ 2  8  1  0  0  1  0 11  0  2  0]\n",
      " [ 0  7  0  0  0  1  0  3 13  1  0]\n",
      " [ 0  6  0  0  0  1  0  2  1 15  0]\n",
      " [ 1  1  0  0  0  0  0  1  2  0  0]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.43119266055045874\n",
      "Test Accuracy\n",
      "0.3803921568627451\n",
      "[[15  6  0  1  0  0  0  0  0  3  0]\n",
      " [ 1 20  0  0  0  2  0  0  0  2  0]\n",
      " [ 4 10  1  0  0  0  0  0  0 10  0]\n",
      " [ 0  0  0 25  0  0  0  0  0  0  0]\n",
      " [ 0 12  0  0 11  0  0  0  0  2  0]\n",
      " [ 4 12  0  0  0  1  0  0  0  8  0]\n",
      " [ 3 14  0  1  0  2  1  0  0  4  0]\n",
      " [ 4 15  0  0  0  0  0  2  0  4  0]\n",
      " [ 1 14  0  0  0  0  0  0  6  4  0]\n",
      " [ 1  9  0  0  0  0  0  0  0 15  0]\n",
      " [ 1  3  0  0  0  0  0  0  0  1  0]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.8125819134993447\n",
      "Test Accuracy\n",
      "0.6627450980392157\n",
      "[[16  7  0  1  0  1  0  0  0  0  0]\n",
      " [ 2 14  0  1  1  3  3  1  0  0  0]\n",
      " [ 0  0 24  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0 25  0  0  0  0  0  0  0]\n",
      " [ 0  4  1  0 20  0  0  0  0  0  0]\n",
      " [ 0 10  0  0  1 12  0  1  0  1  0]\n",
      " [ 1  1  1  1  0  0 18  1  1  1  0]\n",
      " [ 1  7  1  1  0  0  0 15  0  0  0]\n",
      " [ 1  9  0  0  0  1  1  0 13  0  0]\n",
      " [ 1  9  0  0  0  2  0  1  0 12  0]\n",
      " [ 1  3  0  0  0  0  1  0  0  0  0]]\n",
      "\n",
      "\n",
      "USING TFIDF VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.9043250327653998\n",
      "Test Accuracy\n",
      "0.6745098039215687\n",
      "[[18  3  0  1  1  0  0  2  0  0  0]\n",
      " [ 1 14  0  1  0  5  1  2  1  0  0]\n",
      " [ 0  0 24  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0 25  0  0  0  0  0  0  0]\n",
      " [ 1  2  1  0 20  1  0  0  0  0  0]\n",
      " [ 3  4  0  0  1 13  1  1  0  2  0]\n",
      " [ 1  2  1  1  0  2 16  0  2  0  0]\n",
      " [ 2  4  1  1  0  1  2 14  0  0  0]\n",
      " [ 1  6  0  0  0  2  1  1 13  1  0]\n",
      " [ 2  5  0  0  0  2  0  1  0 15  0]\n",
      " [ 1  1  0  1  0  1  0  1  0  0  0]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.13368283093053734\n",
      "Test Accuracy\n",
      "0.12156862745098039\n",
      "[[ 0  0  8  0 17  0  0  0  0  0  0]\n",
      " [ 0  0  6  0 19  0  0  0  0  0  0]\n",
      " [ 0  0  7  0 18  0  0  0  0  0  0]\n",
      " [ 0  0  5  0 20  0  0  0  0  0  0]\n",
      " [ 0  0  1  0 24  0  0  0  0  0  0]\n",
      " [ 0  0  7  0 18  0  0  0  0  0  0]\n",
      " [ 0  0  5  0 20  0  0  0  0  0  0]\n",
      " [ 0  0  9  0 16  0  0  0  0  0  0]\n",
      " [ 0  0  7  0 18  0  0  0  0  0  0]\n",
      " [ 0  0  6  0 19  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  3  0  0  0  0  0  0]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.7719528178243774\n",
      "Test Accuracy\n",
      "0.6745098039215687\n",
      "[[15  6  0  1  1  1  0  0  0  1  0]\n",
      " [ 2 17  0  1  0  2  2  1  0  0  0]\n",
      " [ 0  0 23  0  1  0  0  1  0  0  0]\n",
      " [ 0  0  0 25  0  0  0  0  0  0  0]\n",
      " [ 0  4  0  0 21  0  0  0  0  0  0]\n",
      " [ 0 10  0  0  1 11  1  0  0  2  0]\n",
      " [ 0  3  1  1  0  1 18  0  1  0  0]\n",
      " [ 1  6  1  1  0  1  0 15  0  0  0]\n",
      " [ 0 10  0  0  0  0  1  0 13  1  0]\n",
      " [ 0 10  0  0  0  1  0  0  0 14  0]\n",
      " [ 0  3  0  0  0  0  1  0  0  1  0]]\n",
      "When Considering URL\n",
      "\n",
      "\n",
      "USING COUNT VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.6697247706422018\n",
      "Test Accuracy\n",
      "0.47058823529411764\n",
      "[[13  4  0  0  0  2  3  2  0  1  0]\n",
      " [ 3  9  0  0  0  5  1  4  2  1  0]\n",
      " [ 1  2 15  0  1  0  3  1  1  1  0]\n",
      " [ 0  2  0 17  0  3  0  0  1  2  0]\n",
      " [ 0  3  0  0 19  0  1  1  0  1  0]\n",
      " [ 0  7  0  0  0 14  1  0  1  2  0]\n",
      " [ 1  3  1  1  0  4 12  1  1  1  0]\n",
      " [ 1  6  2  0  0  2  0  7  2  5  0]\n",
      " [ 3  6  1  0  0  3  2  1  8  1  0]\n",
      " [ 1  8  2  0  0  4  0  3  1  6  0]\n",
      " [ 0  2  0  0  0  1  1  0  1  0  0]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.44036697247706424\n",
      "Test Accuracy\n",
      "0.36470588235294116\n",
      "[[ 8  5  0  0  0  1  2  9  0  0  0]\n",
      " [ 0  1  0  0  0  1  3 20  0  0  0]\n",
      " [ 1  0 13  0  0  0  2  9  0  0  0]\n",
      " [ 0  1  0 16  0  0  0  8  0  0  0]\n",
      " [ 0  2  0  0 11  0  1 11  0  0  0]\n",
      " [ 0  3  0  0  0  6  1 15  0  0  0]\n",
      " [ 0  1  0  0  0  3 10 11  0  0  0]\n",
      " [ 1  1  0  0  0  3  1 19  0  0  0]\n",
      " [ 0  1  0  0  0  1  0 17  6  0  0]\n",
      " [ 0  1  0  0  0  1  1 19  0  3  0]\n",
      " [ 0  3  0  0  0  0  1  1  0  0  0]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.6828309305373526\n",
      "Test Accuracy\n",
      "0.4980392156862745\n",
      "[[13  4  0  1  1  3  1  0  1  1  0]\n",
      " [ 3 11  0  0  2  3  2  3  1  0  0]\n",
      " [ 1  2 16  0  2  0  3  1  0  0  0]\n",
      " [ 3  1  0 18  1  2  0  0  0  0  0]\n",
      " [ 0  2  0  0 20  1  1  1  0  0  0]\n",
      " [ 0  7  0  1  1 15  0  0  1  0  0]\n",
      " [ 1  3  1  1  0  3 12  3  1  0  0]\n",
      " [ 3  8  1  0  0  3  2  8  0  0  0]\n",
      " [ 1  8  1  0  0  4  2  3  6  0  0]\n",
      " [ 2  8  2  0  0  0  1  4  0  8  0]\n",
      " [ 1  0  0  0  0  1  2  1  0  0  0]]\n",
      "\n",
      "\n",
      "USING TFIDF VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.8623853211009175\n",
      "Test Accuracy\n",
      "0.49019607843137253\n",
      "[[13  4  0  0  2  2  3  0  0  1  0]\n",
      " [ 4  8  0  0  2  4  1  3  2  1  0]\n",
      " [ 2  1 15  0  1  0  2  1  1  2  0]\n",
      " [ 1  2  0 19  0  3  0  0  0  0  0]\n",
      " [ 0  2  0  0 20  0  1  1  0  1  0]\n",
      " [ 2  3  1  1  0 13  0  1  2  2  0]\n",
      " [ 0  2  2  1  1  3 11  2  1  2  0]\n",
      " [ 5  3  3  0  0  3  1  6  2  2  0]\n",
      " [ 2  3  1  0  0  2  2  3 12  0  0]\n",
      " [ 2  3  4  0  0  2  3  3  0  8  0]\n",
      " [ 1  1  0  0  0  1  2  0  0  0  0]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.1258191349934469\n",
      "Test Accuracy\n",
      "0.12156862745098039\n",
      "[[ 0  0  3  0 22  0  0  0  0  0  0]\n",
      " [ 0  0  3  0 22  0  0  0  0  0  0]\n",
      " [ 0  0  7  0 18  0  0  0  0  0  0]\n",
      " [ 0  0  1  0 24  0  0  0  0  0  0]\n",
      " [ 0  0  1  0 24  0  0  0  0  0  0]\n",
      " [ 0  0  5  0 20  0  0  0  0  0  0]\n",
      " [ 0  0  2  0 23  0  0  0  0  0  0]\n",
      " [ 0  0  4  0 21  0  0  0  0  0  0]\n",
      " [ 0  0  4  0 21  0  0  0  0  0  0]\n",
      " [ 0  0  2  0 23  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  4  0  0  0  0  0  0]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.6081258191349934\n",
      "Test Accuracy\n",
      "0.47058823529411764\n",
      "[[13  9  0  0  1  0  0  0  0  2  0]\n",
      " [ 3 14  0  1  1  4  1  0  0  1  0]\n",
      " [ 1  5 16  0  1  0  0  0  1  1  0]\n",
      " [ 2  6  0 17  0  0  0  0  0  0  0]\n",
      " [ 0  5  0  0 19  0  0  0  0  1  0]\n",
      " [ 1  8  0  0  0 11  0  0  1  4  0]\n",
      " [ 0  8  0  0  0  3 11  1  0  2  0]\n",
      " [ 1  9  2  1  0  1  3  6  1  1  0]\n",
      " [ 1  8  2  0  0  4  1  0  6  3  0]\n",
      " [ 3 11  1  1  0  2  0  0  0  7  0]\n",
      " [ 0  2  0  1  0  0  2  0  0  0  0]]\n",
      "When Considering body + comments\n",
      "\n",
      "\n",
      "USING COUNT VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.5163826998689384\n",
      "Test Accuracy\n",
      "0.22745098039215686\n",
      "[[ 7  3  2  3  1  0  1  3  1  4  0]\n",
      " [ 4 13  3  2  0  1  0  1  1  0  0]\n",
      " [ 0  0  7  1  0  1  4  8  1  3  0]\n",
      " [ 0  1  9  4  2  0  0  2  2  5  0]\n",
      " [ 1  0  4  0  9  0  2  5  1  3  0]\n",
      " [ 0  7  5  0  0  3  2  1  4  3  0]\n",
      " [ 0  2 11  2  1  1  3  2  2  1  0]\n",
      " [ 3  0  6  4  2  2  5  0  1  2  0]\n",
      " [ 2  1  6  2  1  3  1  3  5  1  0]\n",
      " [ 0  1  5  4  1  0  1  2  5  6  0]\n",
      " [ 0  1  1  0  0  0  1  0  1  0  1]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.46526867627785057\n",
      "Test Accuracy\n",
      "0.2235294117647059\n",
      "[[10  3  0 11  0  1  0  0  0  0  0]\n",
      " [ 4 12  1  5  0  3  0  0  0  0  0]\n",
      " [ 3  0  1 20  0  1  0  0  0  0  0]\n",
      " [ 5  2  1 17  0  0  0  0  0  0  0]\n",
      " [ 4  1  1 10  9  0  0  0  0  0  0]\n",
      " [ 4  7  0  7  0  7  0  0  0  0  0]\n",
      " [ 4  1  0 18  0  2  0  0  0  0  0]\n",
      " [ 6  2  0 14  0  1  1  0  1  0  0]\n",
      " [ 4  6  0 11  0  3  0  0  1  0  0]\n",
      " [ 3  1  0 17  0  4  0  0  0  0  0]\n",
      " [ 3  0  0  1  0  1  0  0  0  0  0]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.8099606815203145\n",
      "Test Accuracy\n",
      "0.45098039215686275\n",
      "[[12  0  4  3  0  1  3  1  1  0  0]\n",
      " [ 1 19  2  2  0  0  0  0  0  1  0]\n",
      " [ 0  0  9  8  1  1  4  0  0  2  0]\n",
      " [ 2  4  3 11  0  0  1  1  0  3  0]\n",
      " [ 0  1  1  7 14  0  1  0  0  1  0]\n",
      " [ 0  3  0  4  0 16  0  0  0  2  0]\n",
      " [ 2  1  5  7  0  3  5  1  0  1  0]\n",
      " [ 5  0  5  5  0  0  3  6  0  1  0]\n",
      " [ 1  3  1  6  0  0  0  0 11  3  0]\n",
      " [ 3  0  1  7  0  3  0  0  0 11  0]\n",
      " [ 1  0  0  1  0  0  1  0  1  0  1]]\n",
      "\n",
      "\n",
      "USING TFIDF VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.7522935779816514\n",
      "Test Accuracy\n",
      "0.3607843137254902\n",
      "[[ 9  1  3  4  1  0  1  1  2  3  0]\n",
      " [ 3 12  0  3  1  3  0  2  1  0  0]\n",
      " [ 1  0 10  3  1  2  2  3  0  3  0]\n",
      " [ 3  3  2  9  1  1  1  1  0  4  0]\n",
      " [ 3  1  1  4 10  1  1  3  0  1  0]\n",
      " [ 1  7  1  3  0 10  1  1  0  1  0]\n",
      " [ 1  2  5  3  0  1  9  2  0  2  0]\n",
      " [ 5  4  2  4  2  2  3  1  0  2  0]\n",
      " [ 3  2  0  5  0  2  2  0 10  1  0]\n",
      " [ 2  1  1  4  2  2  1  0  0 12  0]\n",
      " [ 1  1  0  1  0  1  0  0  1  0  0]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.13761467889908258\n",
      "Test Accuracy\n",
      "0.13725490196078433\n",
      "[[ 0 19  0  6  0  0  0  0  0  0  0]\n",
      " [ 0 23  0  2  0  0  0  0  0  0  0]\n",
      " [ 0 12  0 13  0  0  0  0  0  0  0]\n",
      " [ 0 13  0 12  0  0  0  0  0  0  0]\n",
      " [ 0 19  0  6  0  0  0  0  0  0  0]\n",
      " [ 0 21  0  4  0  0  0  0  0  0  0]\n",
      " [ 0 17  0  8  0  0  0  0  0  0  0]\n",
      " [ 0 17  0  8  0  0  0  0  0  0  0]\n",
      " [ 0 17  0  8  0  0  0  0  0  0  0]\n",
      " [ 0 17  0  8  0  0  0  0  0  0  0]\n",
      " [ 0  4  0  1  0  0  0  0  0  0  0]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.747051114023591\n",
      "Test Accuracy\n",
      "0.3686274509803922\n",
      "[[ 7  2  1  0  2  0  2  2  2  7  0]\n",
      " [ 1 18  0  2  1  1  0  0  0  2  0]\n",
      " [ 1  0  7  8  0  1  2  0  1  5  0]\n",
      " [ 4  4  2  8  1  0  1  0  0  5  0]\n",
      " [ 1  1  0  4 10  0  2  2  1  4  0]\n",
      " [ 0  3  1  3  0 16  0  0  0  2  0]\n",
      " [ 3  1  3  6  0  2  7  2  0  1  0]\n",
      " [ 4  1  2  5  1  0  5  4  0  3  0]\n",
      " [ 1  3  2  5  0  0  1  0 13  0  0]\n",
      " [ 1  2  4  6  1  1  1  5  1  3  0]\n",
      " [ 0  0  0  1  0  0  1  1  1  0  1]]\n",
      "When Considering All Params\n",
      "\n",
      "\n",
      "USING COUNT VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.6841415465268676\n",
      "Test Accuracy\n",
      "0.4\n",
      "[[ 7  2  1  2  2  0  2  3  3  2  1]\n",
      " [ 3 17  0  0  1  1  0  1  1  1  0]\n",
      " [ 2  0 17  0  2  1  3  0  0  0  0]\n",
      " [ 2  1  0 11  0  0  5  3  1  1  1]\n",
      " [ 1  1  0  1 10  0  3  7  0  2  0]\n",
      " [ 1  6  0  0  0 13  1  1  3  0  0]\n",
      " [ 2  2  0  8  1  1  5  1  2  3  0]\n",
      " [ 4  0  1  2  3  1  3  4  3  3  1]\n",
      " [ 2  2  0  2  1  3  0  3  8  4  0]\n",
      " [ 1  2  0  2  0  0  4  3  4  9  0]\n",
      " [ 0  0  0  0  1  0  1  0  1  1  1]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.7640891218872871\n",
      "Test Accuracy\n",
      "0.43137254901960786\n",
      "[[11  3  1  2  0  1  0  1  0  6  0]\n",
      " [ 4 11  0  2  1  3  1  0  1  2  0]\n",
      " [ 2  0 17  1  0  1  2  0  0  2  0]\n",
      " [ 5  2  0 18  0  0  0  0  0  0  0]\n",
      " [ 3  1  0  2 10  0  2  1  0  6  0]\n",
      " [ 3  9  0  1  0  6  2  0  0  4  0]\n",
      " [ 2  1  1  7  0  2  7  1  1  3  0]\n",
      " [ 4  2  2  4  0  2  3  4  0  4  0]\n",
      " [ 4  6  0  0  0  3  1  0  7  4  0]\n",
      " [ 1  2  0  0  0  3  0  0  0 19  0]\n",
      " [ 3  0  0  0  0  1  1  0  0  0  0]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.9541284403669725\n",
      "Test Accuracy\n",
      "0.8274509803921568\n",
      "[[21  1  0  1  0  0  0  0  1  1  0]\n",
      " [ 0 23  0  1  0  0  0  1  0  0  0]\n",
      " [ 0  0 21  1  0  1  0  1  0  1  0]\n",
      " [ 1  1  0 23  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0 23  0  0  0  0  1  0]\n",
      " [ 0  3  0  0  0 22  0  0  0  0  0]\n",
      " [ 0  1  1  4  0  2 14  0  0  3  0]\n",
      " [ 2  0  2  1  0  0  3 15  0  2  0]\n",
      " [ 0  1  0  0  0  1  0  0 23  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 25  0]\n",
      " [ 0  0  0  0  0  0  1  1  1  1  1]]\n",
      "\n",
      "\n",
      "USING TFIDF VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.9017038007863696\n",
      "Test Accuracy\n",
      "0.6823529411764706\n",
      "[[20  2  1  1  0  0  0  0  1  0  0]\n",
      " [ 2 18  0  0  0  3  0  1  1  0  0]\n",
      " [ 0  0 21  1  1  1  0  1  0  0  0]\n",
      " [ 2  2  0 19  0  1  0  1  0  0  0]\n",
      " [ 2  1  0  0 20  0  0  2  0  0  0]\n",
      " [ 1  4  0  0  0 18  0  1  1  0  0]\n",
      " [ 1  3  1  2  0  1 15  1  1  0  0]\n",
      " [ 4  3  2  1  1  1  3  8  1  1  0]\n",
      " [ 3  2  0  0  0  2  1  0 17  0  0]\n",
      " [ 1  2  0  0  0  2  0  2  0 18  0]\n",
      " [ 0  1  0  0  1  0  1  0  1  1  0]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.13237221494102228\n",
      "Test Accuracy\n",
      "0.11372549019607843\n",
      "[[ 0 20  0  0  0  0  5  0  0  0  0]\n",
      " [ 0 25  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  0  0  0  0 12  0  0  0  0]\n",
      " [ 0 15  0  0  0  0 10  0  0  0  0]\n",
      " [ 0 19  0  0  0  0  6  0  0  0  0]\n",
      " [ 0 23  0  0  0  0  2  0  0  0  0]\n",
      " [ 0 21  0  0  0  0  4  0  0  0  0]\n",
      " [ 0 21  0  0  0  0  4  0  0  0  0]\n",
      " [ 0 21  0  0  0  0  4  0  0  0  0]\n",
      " [ 0 19  0  0  0  0  6  0  0  0  0]\n",
      " [ 0  4  0  0  0  0  1  0  0  0  0]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.9043250327653998\n",
      "Test Accuracy\n",
      "0.6862745098039216\n",
      "[[ 4  2  1  2  1  1  2  1  1 10  0]\n",
      " [ 0 18  0  0  0  3  0  0  2  2  0]\n",
      " [ 1  1 20  1  1  0  0  0  0  1  0]\n",
      " [ 1  2  0 22  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 24  0  0  0  0  1  0]\n",
      " [ 0  3  0  0  0 22  0  0  0  0  0]\n",
      " [ 2  2  1  1  0  1 14  0  1  3  0]\n",
      " [ 5  0  1  0  0  0  2 10  0  7  0]\n",
      " [ 0  1  0  0  0  1  0  0 22  1  0]\n",
      " [ 5  1  0  0  0  0  1  0  0 18  0]\n",
      " [ 0  0  0  0  0  0  1  0  1  2  1]]\n"
     ]
    }
   ],
   "source": [
    "y = df[\"flair\"]\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "for i in choice_X:\n",
    "    print(\"When Considering\", i)\n",
    "    print(\"\\n\\nUSING COUNT VECTORIZER\")\n",
    "    x_input = choice_X[i]\n",
    "    print(\"Logistic Regression\")\n",
    "    cvec_Logistic(x_input, y)\n",
    "    print(\"Support Vector Classifier\")\n",
    "    cvec_SVC(x_input, y)\n",
    "    print(\"Random Forest Classifier\")\n",
    "    cvec_RF(x_input, y)\n",
    "    \n",
    "    print(\"\\n\\nUSING TFIDF VECTORIZER\")\n",
    "    print(\"Logistic Regression\")\n",
    "    tvec_Logistic(x_input, y)\n",
    "    print(\"Support Vector Classifier\")\n",
    "    tvec_SVC(x_input, y)\n",
    "    print(\"Random Forest Classifier\")\n",
    "    tvec_RF(x_input, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **We observe that the Reddiquete Flair is not being predicted by any of the models present, which may be due to low number of data (both training and testing) available, and hence it is safe to neglect the Reddiquete flair**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reddiquette is the last column and last row of the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sports',\n",
       " 'Politics',\n",
       " 'AskIndia',\n",
       " 'Business/Finance',\n",
       " 'Food',\n",
       " 'Science/Technology',\n",
       " 'Non-Political',\n",
       " 'Photography',\n",
       " 'Policy/Economy',\n",
       " 'Scheduled',\n",
       " '[R]eddiquette']"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flairs = [\"Sports\", \"Politics\", \"AskIndia\", \"Business/Finance\", \"Food\", \"Science/Technology\", \"Non-Political\", \"Photography\", \"Policy/Economy\", \"Scheduled\", \"[R]eddiquette\"]\n",
    "\n",
    "flairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[R]eddiquette'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flairs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sports', 'Politics', 'AskIndia', 'Business/Finance', 'Food',\n",
       "       'Science/Technology', 'Non-Political', 'Photography',\n",
       "       'Policy/Economy', 'Scheduled'], dtype=object)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df1 contains all the values except where flair is Reddiquette\n",
    "df1 = df[df[\"flair\"] != '[R]eddiquette']\n",
    "\n",
    "df1[\"flair\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DOING THE SAME PROCESS OVER FOR `df1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1[\"flair\"]\n",
    "choice_X = {\n",
    "    \"body\": df1[\"lemmatized_body_only\"],\n",
    "    \"comments\": df1[\"lemmatized_comments_only\"], \n",
    "     \"title\": df1[\"lemmatized_title\"],\n",
    "    \"URL\": df1[\"processed_url\"],\n",
    "    \"body + comments\": df1[\"lemmatized_body_comments\"],\n",
    "    \"All Params\": df1[\"lemmatized_all_params\"] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_sheet = []\n",
    "\n",
    "accuracy_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When Considering body\n",
      "\n",
      "\n",
      "USING COUNT VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.492\n",
      "Test Accuracy\n",
      "0.232\n",
      "[[ 1  3  3  4  1  1  1  4  4  3]\n",
      " [ 0  9  5  0  1  2  0  4  3  1]\n",
      " [ 0  0 19  0  1  0  0  4  0  1]\n",
      " [ 1  2 15  1  0  0  2  3  0  1]\n",
      " [ 0  0  9  0 14  0  0  1  1  0]\n",
      " [ 0  5 13  0  0  3  0  2  2  0]\n",
      " [ 0  1 16  1  1  0  2  3  0  1]\n",
      " [ 2  1  9  1  2  0  2  4  1  3]\n",
      " [ 2  3 12  1  0  2  0  2  3  0]\n",
      " [ 0  1 10  1  2  0  2  2  5  2]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.39066666666666666\n",
      "Test Accuracy\n",
      "0.236\n",
      "[[12  0  6  1  0  6  0  0  0  0]\n",
      " [ 5  2  5  0  0 11  0  1  1  0]\n",
      " [ 1  0 24  0  0  0  0  0  0  0]\n",
      " [ 4  2 19  0  0  0  0  0  0  0]\n",
      " [ 1  1 10  0 13  0  0  0  0  0]\n",
      " [ 3  1 13  0  0  8  0  0  0  0]\n",
      " [ 6  1 17  0  0  1  0  0  0  0]\n",
      " [ 6  1 15  0  0  3  0  0  0  0]\n",
      " [ 4  1 13  0  0  7  0  0  0  0]\n",
      " [ 6  0 15  0  0  4  0  0  0  0]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.6253333333333333\n",
      "Test Accuracy\n",
      "0.436\n",
      "[[18  1  1  0  0  2  0  2  1  0]\n",
      " [ 2 18  5  0  0  0  0  0  0  0]\n",
      " [ 2  0 22  0  0  0  0  1  0  0]\n",
      " [ 6  3 14  1  0  0  0  0  1  0]\n",
      " [ 2  0  9  0 14  0  0  0  0  0]\n",
      " [ 0  1 13  0  0 11  0  0  0  0]\n",
      " [ 4  0 15  1  0  3  0  2  0  0]\n",
      " [13  0  9  0  0  0  0  3  0  0]\n",
      " [ 0  2 12  0  0  1  0  0 10  0]\n",
      " [ 1  0 10  0  0  2  0  0  0 12]]\n",
      "\n",
      "\n",
      "USING TFIDF VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.52\n",
      "Test Accuracy\n",
      "0.324\n",
      "[[11  1  1  3  0  2  0  3  2  2]\n",
      " [ 2 12  5  0  0  6  0  0  0  0]\n",
      " [ 0  0 23  1  0  0  0  1  0  0]\n",
      " [ 2  3 13  0  0  2  2  2  0  1]\n",
      " [ 0  0  9  0 14  1  0  0  1  0]\n",
      " [ 2  2 13  0  0  7  0  1  0  0]\n",
      " [ 2  2 15  0  0  3  1  1  1  0]\n",
      " [ 5  3  9  1  2  1  1  3  0  0]\n",
      " [ 4  4 12  0  0  3  0  0  2  0]\n",
      " [ 2  1 10  0  0  4  0  0  0  8]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.15466666666666667\n",
      "Test Accuracy\n",
      "0.168\n",
      "[[20  0  5  0  0  0  0  0  0  0]\n",
      " [20  0  5  0  0  0  0  0  0  0]\n",
      " [ 3  0 22  0  0  0  0  0  0  0]\n",
      " [ 8  0 17  0  0  0  0  0  0  0]\n",
      " [15  0 10  0  0  0  0  0  0  0]\n",
      " [12  0 13  0  0  0  0  0  0  0]\n",
      " [10  0 15  0  0  0  0  0  0  0]\n",
      " [13  0 12  0  0  0  0  0  0  0]\n",
      " [12  0 13  0  0  0  0  0  0  0]\n",
      " [14  0 11  0  0  0  0  0  0  0]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.608\n",
      "Test Accuracy\n",
      "0.328\n",
      "[[14  1  0  1  2  1  0  5  1  0]\n",
      " [ 1 13  0  0  0  6  5  0  0  0]\n",
      " [ 1  0  4  0  0  0 19  1  0  0]\n",
      " [ 5  3  0  0  0  0 14  2  0  1]\n",
      " [ 2  0  0  0 13  0  9  0  1  0]\n",
      " [ 0  1  0  0  0 11 13  0  0  0]\n",
      " [ 5  1  0  1  0  2 15  1  0  0]\n",
      " [ 7  2  0  1  2  0  9  2  0  2]\n",
      " [ 0  1  0  0  0  2 12  0 10  0]\n",
      " [10  0  0  1  0  0 10  4  0  0]]\n",
      "When Considering comments\n",
      "\n",
      "\n",
      "USING COUNT VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.52\n",
      "Test Accuracy\n",
      "0.148\n",
      "[[ 4  0  1  7  1  0  0  5  2  5]\n",
      " [ 0  4  2  7  4  0  1  3  2  2]\n",
      " [ 1  2  4  4  4  2  1  1  2  4]\n",
      " [ 2  2  1  8  1  1  1  1  2  6]\n",
      " [ 0  0  1  7  4  2  1  4  2  4]\n",
      " [ 0  2  1  9  3  5  1  0  3  1]\n",
      " [ 0  3  2 10  2  2  3  1  1  1]\n",
      " [ 1  2  0  9  3  0  4  2  0  4]\n",
      " [ 2  5  0  8  1  2  3  2  1  1]\n",
      " [ 1  2  4  7  5  1  1  0  2  2]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.204\n",
      "Test Accuracy\n",
      "0.124\n",
      "[[ 0  0  0  0  0  0  0  0  1 24]\n",
      " [ 1  2  0  1  0  0  0  0  1 20]\n",
      " [ 0  1  0  0  1  1  0  1  0 21]\n",
      " [ 1  1  0  0  0  0  0  0  0 23]\n",
      " [ 0  0  0  0  3  0  0  1  0 21]\n",
      " [ 0  1  0  0  0  1  0  1  1 21]\n",
      " [ 0  0  0  0  1  0  0  0  1 23]\n",
      " [ 1  1  0  0  0  0  2  1  0 20]\n",
      " [ 2  2  0  0  1  0  0  0  1 19]\n",
      " [ 0  0  0  0  0  1  0  0  1 23]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.62\n",
      "Test Accuracy\n",
      "0.18\n",
      "[[ 3  1  1  6  2  1  3  3  1  4]\n",
      " [ 0  3  2 10  2  3  0  2  0  3]\n",
      " [ 2  2  4  7  1  2  2  2  0  3]\n",
      " [ 0  3  1  9  3  1  2  0  0  6]\n",
      " [ 0  0  1  9  5  1  2  4  0  3]\n",
      " [ 0  3  0  8  0  6  3  4  0  1]\n",
      " [ 0  1  0  8  1  4  5  0  0  6]\n",
      " [ 2  2  1  8  1  1  4  2  1  3]\n",
      " [ 2  4  0 10  0  3  3  1  2  0]\n",
      " [ 0  0  2 10  2  4  0  0  1  6]]\n",
      "\n",
      "\n",
      "USING TFIDF VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.6826666666666666\n",
      "Test Accuracy\n",
      "0.164\n",
      "[[1 2 2 6 1 2 2 5 3 1]\n",
      " [2 5 1 7 2 3 1 3 0 1]\n",
      " [2 3 7 3 3 4 0 2 1 0]\n",
      " [3 1 1 7 3 2 1 1 3 3]\n",
      " [2 0 3 6 6 3 2 2 0 1]\n",
      " [0 2 1 9 1 4 6 2 0 0]\n",
      " [2 4 2 5 3 3 4 1 0 1]\n",
      " [3 5 1 6 0 2 3 2 1 2]\n",
      " [2 6 0 8 0 1 3 3 1 1]\n",
      " [2 2 2 5 2 3 2 3 0 4]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.11866666666666667\n",
      "Test Accuracy\n",
      "0.108\n",
      "[[ 0  9  0 16  0  0  0  0  0  0]\n",
      " [ 0 10  0 15  0  0  0  0  0  0]\n",
      " [ 0 11  0 14  0  0  0  0  0  0]\n",
      " [ 0  8  0 17  0  0  0  0  0  0]\n",
      " [ 0  5  0 20  0  0  0  0  0  0]\n",
      " [ 0 11  0 14  0  0  0  0  0  0]\n",
      " [ 0  9  0 16  0  0  0  0  0  0]\n",
      " [ 0  9  0 16  0  0  0  0  0  0]\n",
      " [ 0 12  0 13  0  0  0  0  0  0]\n",
      " [ 0  8  0 17  0  0  0  0  0  0]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.524\n",
      "Test Accuracy\n",
      "0.16\n",
      "[[ 7  0  3  6  1  0  1  2  2  3]\n",
      " [ 2  3  3  8  2  2  1  3  1  0]\n",
      " [ 2  1  4  4  2  1  3  4  0  4]\n",
      " [ 1  3  2  9  1  1  0  5  2  1]\n",
      " [ 2  0  2  7  4  2  2  3  0  3]\n",
      " [ 1  1  2 10  4  4  1  2  0  0]\n",
      " [ 1  2  2  8  3  3  5  0  0  1]\n",
      " [ 4  2  3  7  3  0  3  2  0  1]\n",
      " [ 3  4  0  9  0  1  3  2  1  2]\n",
      " [ 2  3  0  7  4  2  1  5  0  1]]\n",
      "When Considering title\n",
      "\n",
      "\n",
      "USING COUNT VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.8346666666666667\n",
      "Test Accuracy\n",
      "0.696\n",
      "[[14  3  0  0  0  2  0  3  0  3]\n",
      " [ 2 14  0  0  0  6  2  0  0  1]\n",
      " [ 0  0 24  0  0  0  0  1  0  0]\n",
      " [ 0  0  0 25  0  0  0  0  0  0]\n",
      " [ 0  3  1  0 20  0  0  1  0  0]\n",
      " [ 2  6  0  0  0 16  0  1  0  0]\n",
      " [ 0  1  1  0  0  1 20  0  1  1]\n",
      " [ 2  6  1  0  0  1  0 12  0  3]\n",
      " [ 0  7  0  0  0  1  0  2 14  1]\n",
      " [ 0  7  0  0  0  2  0  1  0 15]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.46266666666666667\n",
      "Test Accuracy\n",
      "0.408\n",
      "[[14  6  0  0  0  0  0  1  0  4]\n",
      " [ 1 20  0  0  0  2  1  0  0  1]\n",
      " [ 1 14  2  0  0  0  0  0  0  8]\n",
      " [ 0  0  0 25  0  0  0  0  0  0]\n",
      " [ 0  8  0  0 16  0  0  0  0  1]\n",
      " [ 2 19  0  0  0  2  0  0  0  2]\n",
      " [ 4 17  0  0  0  0  2  0  0  2]\n",
      " [ 2 18  0  0  0  0  0  2  0  3]\n",
      " [ 1 16  0  0  0  0  0  0  6  2]\n",
      " [ 1 11  0  0  0  0  0  0  0 13]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.8106666666666666\n",
      "Test Accuracy\n",
      "0.704\n",
      "[[19  5  0  0  0  0  0  1  0  0]\n",
      " [ 2 17  0  1  0  3  1  0  0  1]\n",
      " [ 0  0 24  0  0  0  0  1  0  0]\n",
      " [ 0  0  0 25  0  0  0  0  0  0]\n",
      " [ 1  2  1  0 21  0  0  0  0  0]\n",
      " [ 0  8  0  0  1 13  0  3  0  0]\n",
      " [ 1  1  2  3  0  0 17  1  0  0]\n",
      " [ 1  8  1  0  0  0  0 15  0  0]\n",
      " [ 2  6  0  0  0  1  1  0 13  2]\n",
      " [ 1 10  0  0  0  1  0  1  0 12]]\n",
      "\n",
      "\n",
      "USING TFIDF VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.9146666666666666\n",
      "Test Accuracy\n",
      "0.724\n",
      "[[18  2  0  0  0  0  0  3  1  1]\n",
      " [ 2 13  0  1  0  7  1  0  1  0]\n",
      " [ 0  0 24  0  0  0  0  1  0  0]\n",
      " [ 0  0  0 25  0  0  0  0  0  0]\n",
      " [ 0  2  1  0 21  0  0  0  0  1]\n",
      " [ 3  5  0  0  1 15  0  1  0  0]\n",
      " [ 2  0  1  0  0  0 20  1  0  1]\n",
      " [ 2  3  1  0  0  1  0 17  0  1]\n",
      " [ 1  5  0  0  0  2  2  0 13  2]\n",
      " [ 1  4  0  0  0  1  1  2  1 15]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.136\n",
      "Test Accuracy\n",
      "0.124\n",
      "[[ 0  0  9  0 16  0  0  0  0  0]\n",
      " [ 0  0  8  0 17  0  0  0  0  0]\n",
      " [ 0  0  7  0 18  0  0  0  0  0]\n",
      " [ 0  0  4  0 21  0  0  0  0  0]\n",
      " [ 0  0  1  0 24  0  0  0  0  0]\n",
      " [ 0  0 10  0 15  0  0  0  0  0]\n",
      " [ 0  0  7  0 18  0  0  0  0  0]\n",
      " [ 0  0 10  0 15  0  0  0  0  0]\n",
      " [ 0  0  7  0 18  0  0  0  0  0]\n",
      " [ 0  0  6  0 19  0  0  0  0  0]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.7626666666666667\n",
      "Test Accuracy\n",
      "0.712\n",
      "[[16  4  0  0  0  1  0  2  0  2]\n",
      " [ 2 19  0  1  0  3  0  0  0  0]\n",
      " [ 0  1 24  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 25  0  0  0  0  0  0]\n",
      " [ 0  3  1  0 20  1  0  0  0  0]\n",
      " [ 0 10  0  0  0 14  0  1  0  0]\n",
      " [ 1  2  1  0  0  0 20  0  0  1]\n",
      " [ 1  7  1  0  0  1  0 15  0  0]\n",
      " [ 0 10  0  0  0  1  0  0 13  1]\n",
      " [ 1 10  0  0  0  1  0  1  0 12]]\n",
      "When Considering URL\n",
      "\n",
      "\n",
      "USING COUNT VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.6586666666666666\n",
      "Test Accuracy\n",
      "0.508\n",
      "[[12  3  0  0  0  1  1  3  2  3]\n",
      " [ 2  9  0  0  0  5  0  3  3  3]\n",
      " [ 0  3 16  0  0  0  3  0  1  2]\n",
      " [ 1  1  1 17  0  2  1  0  1  1]\n",
      " [ 0  3  0  0 19  0  0  2  0  1]\n",
      " [ 0  6  0  0  0 16  0  1  1  1]\n",
      " [ 1  2  2  0  0  1 13  1  2  3]\n",
      " [ 1  3  2  0  0  2  0  9  3  5]\n",
      " [ 1  6  1  0  0  1  1  3 11  1]\n",
      " [ 2 10  2  0  0  3  0  2  1  5]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.444\n",
      "Test Accuracy\n",
      "0.388\n",
      "[[ 9  4  0  0  0  0  1 10  1  0]\n",
      " [ 0  1  0  0  0  1  2 20  0  1]\n",
      " [ 0  0 12  0  0  1  3  9  0  0]\n",
      " [ 0  2  0 15  0  0  1  7  0  0]\n",
      " [ 0  2  0  0 13  0  0 10  0  0]\n",
      " [ 0  2  0  0  0  8  2 13  0  0]\n",
      " [ 0  1  0  0  0  0 13 11  0  0]\n",
      " [ 1  2  0  0  0  2  3 17  0  0]\n",
      " [ 0  1  0  0  0  1  3 14  6  0]\n",
      " [ 0  1  0  0  0  1  1 19  0  3]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.6973333333333334\n",
      "Test Accuracy\n",
      "0.556\n",
      "[[14  7  0  0  0  0  1  1  1  1]\n",
      " [ 4 12  0  0  1  3  0  1  1  3]\n",
      " [ 3  3 18  0  1  0  0  0  0  0]\n",
      " [ 1  3  0 19  1  1  0  0  0  0]\n",
      " [ 0  3  0  0 21  0  0  1  0  0]\n",
      " [ 0  9  0  0  1 13  1  0  0  1]\n",
      " [ 3  5  0  1  0  1 13  1  0  1]\n",
      " [ 3  9  1  0  0  1  1  9  1  0]\n",
      " [ 1  8  1  0  0  2  0  0 12  1]\n",
      " [ 2  9  2  0  0  1  0  3  0  8]]\n",
      "\n",
      "\n",
      "USING TFIDF VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.8813333333333333\n",
      "Test Accuracy\n",
      "0.536\n",
      "[[14  4  0  1  1  1  2  1  0  1]\n",
      " [ 4  8  0  0  1  7  0  3  0  2]\n",
      " [ 0  3 17  0  0  0  0  0  2  3]\n",
      " [ 1  2  0 19  0  2  1  0  0  0]\n",
      " [ 0  1  0  0 21  1  0  1  1  0]\n",
      " [ 0  1  0  0  3 14  1  3  2  1]\n",
      " [ 1  1  2  0  2  1 14  1  1  2]\n",
      " [ 5  2  4  0  0  3  1  7  2  1]\n",
      " [ 1  3  1  0  0  1  3  2 13  1]\n",
      " [ 2  1  3  1  0  2  3  5  1  7]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.128\n",
      "Test Accuracy\n",
      "0.124\n",
      "[[ 0  0  4  0 21  0  0  0  0  0]\n",
      " [ 0  0  4  0 21  0  0  0  0  0]\n",
      " [ 0  0  6  0 19  0  0  0  0  0]\n",
      " [ 0  0  0  0 25  0  0  0  0  0]\n",
      " [ 0  0  0  0 25  0  0  0  0  0]\n",
      " [ 0  0  5  0 20  0  0  0  0  0]\n",
      " [ 0  0  3  0 22  0  0  0  0  0]\n",
      " [ 0  0  5  0 20  0  0  0  0  0]\n",
      " [ 0  0  4  0 21  0  0  0  0  0]\n",
      " [ 0  0  2  0 23  0  0  0  0  0]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.6146666666666667\n",
      "Test Accuracy\n",
      "0.516\n",
      "[[13  8  0  0  0  1  0  2  0  1]\n",
      " [ 2 16  0  0  0  5  0  2  0  0]\n",
      " [ 0  5 17  0  0  0  0  0  0  3]\n",
      " [ 1  6  0 16  0  1  0  1  0  0]\n",
      " [ 0  5  0  0 19  0  0  1  0  0]\n",
      " [ 0 11  0  1  0 11  0  1  0  1]\n",
      " [ 0 10  0  0  0  0 13  0  0  2]\n",
      " [ 3  8  1  0  0  1  2  8  0  2]\n",
      " [ 1 15  1  0  0  1  0  0  7  0]\n",
      " [ 1  9  2  0  0  1  0  3  0  9]]\n",
      "When Considering body + comments\n",
      "\n",
      "\n",
      "USING COUNT VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.5533333333333333\n",
      "Test Accuracy\n",
      "0.252\n",
      "[[ 2  2  4  2  1  0  0  4  6  4]\n",
      " [ 3 11  4  0  1  1  0  1  2  2]\n",
      " [ 1  1  8  2  1  0  1  6  1  4]\n",
      " [ 2  1  6  5  3  0  4  0  1  3]\n",
      " [ 1  0  5  0 15  0  0  0  2  2]\n",
      " [ 1  2  7  0  0  7  1  2  3  2]\n",
      " [ 0  1  9  2  1  1  4  3  0  4]\n",
      " [ 3  0  5  3  3  0  5  1  3  2]\n",
      " [ 2  1  7  1  1  3  1  3  4  2]\n",
      " [ 0  1  4  4  2  0  1  3  4  6]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.4706666666666667\n",
      "Test Accuracy\n",
      "0.24\n",
      "[[ 8  4  0  7  0  3  0  2  1  0]\n",
      " [ 3 10  1  4  0  7  0  0  0  0]\n",
      " [ 1  0  1 22  0  1  0  0  0  0]\n",
      " [ 4  2  0 19  0  0  0  0  0  0]\n",
      " [ 2  1  0  9 13  0  0  0  0  0]\n",
      " [ 3  3  0 12  0  7  0  0  0  0]\n",
      " [ 5  1  0 17  0  1  0  0  0  1]\n",
      " [ 4  2  0 13  0  2  1  1  1  1]\n",
      " [ 4  6  0 11  0  3  0  0  1  0]\n",
      " [ 3  0  0 17  0  5  0  0  0  0]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.8026666666666666\n",
      "Test Accuracy\n",
      "0.456\n",
      "[[14  1  1  0  0  1  1  3  2  2]\n",
      " [ 0 21  0  2  0  0  0  1  0  1]\n",
      " [ 1  0  5 14  1  1  2  0  0  1]\n",
      " [ 4  3  1 11  1  0  2  0  0  3]\n",
      " [ 0  0  1  7 15  0  0  0  1  1]\n",
      " [ 0  1  1  6  0 13  0  1  0  3]\n",
      " [ 3  1  4  7  0  3  4  2  0  1]\n",
      " [ 4  0  2  2  1  0  2  8  1  5]\n",
      " [ 0  3  0  8  0  1  1  1 11  0]\n",
      " [ 2  0  0  9  0  2  0  0  0 12]]\n",
      "\n",
      "\n",
      "USING TFIDF VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.7573333333333333\n",
      "Test Accuracy\n",
      "0.384\n",
      "[[ 8  1  1  4  1  2  1  3  2  2]\n",
      " [ 1 13  0  3  0  6  0  1  1  0]\n",
      " [ 1  0  8  4  2  2  2  3  0  3]\n",
      " [ 2  4  2  8  1  1  2  2  0  3]\n",
      " [ 0  0  1  2 14  0  0  4  1  3]\n",
      " [ 2  1  0  6  0 11  1  2  0  2]\n",
      " [ 1  2  3  4  1  2 10  1  0  1]\n",
      " [ 5  3  2  3  3  2  3  2  0  2]\n",
      " [ 3  3  0  5  1  2  0  0  9  2]\n",
      " [ 2  1  1  4  2  2  0  0  0 13]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.14133333333333334\n",
      "Test Accuracy\n",
      "0.136\n",
      "[[ 0 21  0  4  0  0  0  0  0  0]\n",
      " [ 0 23  0  2  0  0  0  0  0  0]\n",
      " [ 0 12  0 13  0  0  0  0  0  0]\n",
      " [ 0 14  0 11  0  0  0  0  0  0]\n",
      " [ 0 19  0  6  0  0  0  0  0  0]\n",
      " [ 0 18  0  7  0  0  0  0  0  0]\n",
      " [ 0 17  0  8  0  0  0  0  0  0]\n",
      " [ 0 17  0  8  0  0  0  0  0  0]\n",
      " [ 0 17  0  8  0  0  0  0  0  0]\n",
      " [ 0 17  0  8  0  0  0  0  0  0]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.7733333333333333\n",
      "Test Accuracy\n",
      "0.344\n",
      "[[12  1  1  3  1  0  0  3  2  2]\n",
      " [ 2 13  0  2  0  5  0  1  1  1]\n",
      " [ 2  0  5  7  1  1  3  3  0  3]\n",
      " [ 5  2  2  3  4  0  2  2  0  5]\n",
      " [ 1  0  1  3 13  0  0  2  1  4]\n",
      " [ 2  1  0  6  0 13  0  1  0  2]\n",
      " [ 2  1  1  7  1  4  5  3  0  1]\n",
      " [ 6  2  1  3  1  0  5  6  0  1]\n",
      " [ 1  3  0  5  0  2  1  0 11  2]\n",
      " [ 8  2  1  5  4  0  0  0  0  5]]\n",
      "When Considering All Params\n",
      "\n",
      "\n",
      "USING COUNT VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.6853333333333333\n",
      "Test Accuracy\n",
      "0.42\n",
      "[[ 4  1  1  1  3  0  2  7  5  1]\n",
      " [ 3 14  0  0  0  4  0  2  2  0]\n",
      " [ 2  0 19  0  2  0  2  0  0  0]\n",
      " [ 4  2  1 12  1  0  2  1  1  1]\n",
      " [ 0  0  1  1 15  0  0  3  2  3]\n",
      " [ 2  4  1  0  0 13  0  3  1  1]\n",
      " [ 1  1  0  8  0  0  7  2  2  4]\n",
      " [ 3  0  1  3  2  0  3  5  3  5]\n",
      " [ 2  2  0  1  0  1  1  2  7  9]\n",
      " [ 1  1  0  2  3  0  4  2  3  9]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.7733333333333333\n",
      "Test Accuracy\n",
      "0.468\n",
      "[[ 8  3  1  1  0  5  0  2  1  4]\n",
      " [ 4  3  0  1  0 13  1  1  1  1]\n",
      " [ 1  0 19  0  0  1  0  0  0  4]\n",
      " [ 3  2  0 19  0  0  1  0  0  0]\n",
      " [ 0  1  1  1 16  0  0  1  0  5]\n",
      " [ 2  1  0  0  0 10  5  0  0  7]\n",
      " [ 3  0  0  4  0  2 11  0  1  4]\n",
      " [ 3  1  2  2  0  3  5  5  0  4]\n",
      " [ 4  0  0  0  0  9  1  0  7  4]\n",
      " [ 1  0  0  0  0  5  0  0  0 19]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.9573333333333334\n",
      "Test Accuracy\n",
      "0.828\n",
      "[[18  2  0  0  0  1  0  2  1  1]\n",
      " [ 1 23  0  0  0  0  0  0  0  1]\n",
      " [ 1  0 21  1  0  1  0  0  0  1]\n",
      " [ 0  2  0 23  0  0  0  0  0  0]\n",
      " [ 0  0  1  0 21  0  0  0  1  2]\n",
      " [ 0  3  0  0  0 20  0  0  0  2]\n",
      " [ 0  0  1  0  0  4 18  0  0  2]\n",
      " [ 2  0  2  0  0  0  2 17  0  2]\n",
      " [ 0  2  0  0  0  1  0  0 22  0]\n",
      " [ 0  0  0  0  0  1  0  0  0 24]]\n",
      "\n",
      "\n",
      "USING TFIDF VECTORIZER\n",
      "Logistic Regression\n",
      "Train Accuracy\n",
      "0.904\n",
      "Test Accuracy\n",
      "0.7\n",
      "[[18  2  0  0  0  2  0  2  1  0]\n",
      " [ 1 17  0  0  0  5  0  0  2  0]\n",
      " [ 0  0 22  1  0  1  0  1  0  0]\n",
      " [ 3  2  1 18  0  1  0  0  0  0]\n",
      " [ 0  1  1  0 21  0  0  1  0  1]\n",
      " [ 1  0  1  0  0 20  1  2  0  0]\n",
      " [ 1  0  1  1  0  0 18  2  0  2]\n",
      " [ 3  4  2  1  1  1  2 10  0  1]\n",
      " [ 3  2  0  0  0  2  2  0 16  0]\n",
      " [ 1  1  0  0  0  3  1  4  0 15]]\n",
      "Support Vector Classifier\n",
      "Train Accuracy\n",
      "0.13466666666666666\n",
      "Test Accuracy\n",
      "0.128\n",
      "[[ 0 21  0  4  0  0  0  0  0  0]\n",
      " [ 0 25  0  0  0  0  0  0  0  0]\n",
      " [ 0 15  0 10  0  0  0  0  0  0]\n",
      " [ 0 18  0  7  0  0  0  0  0  0]\n",
      " [ 0 21  0  4  0  0  0  0  0  0]\n",
      " [ 0 21  0  4  0  0  0  0  0  0]\n",
      " [ 0 19  0  6  0  0  0  0  0  0]\n",
      " [ 0 20  0  5  0  0  0  0  0  0]\n",
      " [ 0 21  0  4  0  0  0  0  0  0]\n",
      " [ 0 19  0  6  0  0  0  0  0  0]]\n",
      "Random Forest Classifier\n",
      "Train Accuracy\n",
      "0.92\n",
      "Test Accuracy\n",
      "0.728\n",
      "[[ 8  1  2  0  0  1  1  5  2  5]\n",
      " [ 0 22  0  0  0  1  0  0  1  1]\n",
      " [ 0  0 21  1  0  1  0  0  0  2]\n",
      " [ 0  2  0 22  0  0  0  0  0  1]\n",
      " [ 0  0  1  0 21  0  0  1  1  1]\n",
      " [ 0  2  1  0  0 19  0  1  0  2]\n",
      " [ 2  0  1  0  0  1 17  1  0  3]\n",
      " [ 5  1  1  0  0  0  2 12  0  4]\n",
      " [ 0  0  0  0  0  1  0  0 23  1]\n",
      " [ 4  0  1  0  0  1  0  2  0 17]]\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "for i in choice_X:\n",
    "    print(\"When Considering\", i)\n",
    "    \n",
    "    print(\"\\n\\nUSING COUNT VECTORIZER\")\n",
    "    x_input = choice_X[i]\n",
    "    \n",
    "    print(\"Logistic Regression\")\n",
    "    row_item = []\n",
    "    row_item.append(i)\n",
    "    a,b = cvec_Logistic(x_input, y)\n",
    "    row_item.append(\"Count Vectorizer\")\n",
    "    row_item.append(\"LR\")\n",
    "    row_item.append(a)\n",
    "    row_item.append(b)\n",
    "    accuracy_sheet.append(row_item)\n",
    "    \n",
    "    print(\"Support Vector Classifier\")\n",
    "    c,d = cvec_SVC(x_input, y)\n",
    "    row_item = []\n",
    "    row_item.append(i)\n",
    "    row_item.append(\"Count Vectorizer\")\n",
    "    row_item.append(\"SVC\")\n",
    "    row_item.append(c)\n",
    "    row_item.append(d)\n",
    "    accuracy_sheet.append(row_item)\n",
    "    \n",
    "    print(\"Random Forest Classifier\")\n",
    "    e,f = cvec_RF(x_input, y)\n",
    "    row_item = []\n",
    "    row_item.append(i)\n",
    "    row_item.append(\"Count Vectorizer\")\n",
    "    row_item.append(\"RF\")\n",
    "    row_item.append(e)\n",
    "    row_item.append(f)\n",
    "    accuracy_sheet.append(row_item)\n",
    "    \n",
    "    \n",
    "    print(\"\\n\\nUSING TFIDF VECTORIZER\")\n",
    "    \n",
    "    print(\"Logistic Regression\")\n",
    "    a,b = tvec_Logistic(x_input, y)\n",
    "    row_item = []\n",
    "    row_item.append(i)\n",
    "    row_item.append(\"TFIDF Vectorizer\")\n",
    "    row_item.append(\"LR\")\n",
    "    row_item.append(a)\n",
    "    row_item.append(b)\n",
    "    accuracy_sheet.append(row_item)\n",
    "    \n",
    "    print(\"Support Vector Classifier\")\n",
    "    c,d = tvec_SVC(x_input, y)\n",
    "    row_item = []\n",
    "    row_item.append(i)\n",
    "    row_item.append(\"TFIDF Vectorizer\")\n",
    "    row_item.append(\"SVC\")\n",
    "    row_item.append(c)\n",
    "    row_item.append(d)\n",
    "    accuracy_sheet.append(row_item)\n",
    "    \n",
    "    print(\"Random Forest Classifier\")\n",
    "    e,f = tvec_RF(x_input, y)\n",
    "    row_item = []\n",
    "    row_item.append(i)\n",
    "    row_item.append(\"TFIDF Vectorizer\")\n",
    "    row_item.append(\"RF\")\n",
    "    row_item.append(e)\n",
    "    row_item.append(f)\n",
    "    accuracy_sheet.append(row_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['body', 'Count Vectorizer', 'LR', 0.492, 0.232],\n",
       " ['body', 'Count Vectorizer', 'SVC', 0.39066666666666666, 0.236],\n",
       " ['body', 'Count Vectorizer', 'RF', 0.6253333333333333, 0.436],\n",
       " ['body', 'TFIDF Vectorizer', 'LR', 0.52, 0.324],\n",
       " ['body', 'TFIDF Vectorizer', 'SVC', 0.15466666666666667, 0.168],\n",
       " ['body', 'TFIDF Vectorizer', 'RF', 0.608, 0.328],\n",
       " ['comments', 'Count Vectorizer', 'LR', 0.52, 0.148],\n",
       " ['comments', 'Count Vectorizer', 'SVC', 0.204, 0.124],\n",
       " ['comments', 'Count Vectorizer', 'RF', 0.62, 0.18],\n",
       " ['comments', 'TFIDF Vectorizer', 'LR', 0.6826666666666666, 0.164],\n",
       " ['comments', 'TFIDF Vectorizer', 'SVC', 0.11866666666666667, 0.108],\n",
       " ['comments', 'TFIDF Vectorizer', 'RF', 0.524, 0.16],\n",
       " ['title', 'Count Vectorizer', 'LR', 0.8346666666666667, 0.696],\n",
       " ['title', 'Count Vectorizer', 'SVC', 0.46266666666666667, 0.408],\n",
       " ['title', 'Count Vectorizer', 'RF', 0.8106666666666666, 0.704],\n",
       " ['title', 'TFIDF Vectorizer', 'LR', 0.9146666666666666, 0.724],\n",
       " ['title', 'TFIDF Vectorizer', 'SVC', 0.136, 0.124],\n",
       " ['title', 'TFIDF Vectorizer', 'RF', 0.7626666666666667, 0.712],\n",
       " ['URL', 'Count Vectorizer', 'LR', 0.6586666666666666, 0.508],\n",
       " ['URL', 'Count Vectorizer', 'SVC', 0.444, 0.388],\n",
       " ['URL', 'Count Vectorizer', 'RF', 0.6973333333333334, 0.556],\n",
       " ['URL', 'TFIDF Vectorizer', 'LR', 0.8813333333333333, 0.536],\n",
       " ['URL', 'TFIDF Vectorizer', 'SVC', 0.128, 0.124],\n",
       " ['URL', 'TFIDF Vectorizer', 'RF', 0.6146666666666667, 0.516],\n",
       " ['body + comments', 'Count Vectorizer', 'LR', 0.5533333333333333, 0.252],\n",
       " ['body + comments', 'Count Vectorizer', 'SVC', 0.4706666666666667, 0.24],\n",
       " ['body + comments', 'Count Vectorizer', 'RF', 0.8026666666666666, 0.456],\n",
       " ['body + comments', 'TFIDF Vectorizer', 'LR', 0.7573333333333333, 0.384],\n",
       " ['body + comments', 'TFIDF Vectorizer', 'SVC', 0.14133333333333334, 0.136],\n",
       " ['body + comments', 'TFIDF Vectorizer', 'RF', 0.7733333333333333, 0.344],\n",
       " ['All Params', 'Count Vectorizer', 'LR', 0.6853333333333333, 0.42],\n",
       " ['All Params', 'Count Vectorizer', 'SVC', 0.7733333333333333, 0.468],\n",
       " ['All Params', 'Count Vectorizer', 'RF', 0.9573333333333334, 0.828],\n",
       " ['All Params', 'TFIDF Vectorizer', 'LR', 0.904, 0.7],\n",
       " ['All Params', 'TFIDF Vectorizer', 'SVC', 0.13466666666666666, 0.128],\n",
       " ['All Params', 'TFIDF Vectorizer', 'RF', 0.92, 0.728]]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Considering</th>\n",
       "      <th>Vectorizer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>body</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>LR</td>\n",
       "      <td>49.20</td>\n",
       "      <td>23.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>body</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>SVC</td>\n",
       "      <td>39.07</td>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>body</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>RF</td>\n",
       "      <td>62.53</td>\n",
       "      <td>43.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>body</td>\n",
       "      <td>TFIDF Vectorizer</td>\n",
       "      <td>LR</td>\n",
       "      <td>52.00</td>\n",
       "      <td>32.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>body</td>\n",
       "      <td>TFIDF Vectorizer</td>\n",
       "      <td>SVC</td>\n",
       "      <td>15.47</td>\n",
       "      <td>16.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>body</td>\n",
       "      <td>TFIDF Vectorizer</td>\n",
       "      <td>RF</td>\n",
       "      <td>60.80</td>\n",
       "      <td>32.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>comments</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>LR</td>\n",
       "      <td>52.00</td>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>comments</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>SVC</td>\n",
       "      <td>20.40</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>comments</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>RF</td>\n",
       "      <td>62.00</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>comments</td>\n",
       "      <td>TFIDF Vectorizer</td>\n",
       "      <td>LR</td>\n",
       "      <td>68.27</td>\n",
       "      <td>16.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>comments</td>\n",
       "      <td>TFIDF Vectorizer</td>\n",
       "      <td>SVC</td>\n",
       "      <td>11.87</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>comments</td>\n",
       "      <td>TFIDF Vectorizer</td>\n",
       "      <td>RF</td>\n",
       "      <td>52.40</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>title</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>LR</td>\n",
       "      <td>83.47</td>\n",
       "      <td>69.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>title</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>SVC</td>\n",
       "      <td>46.27</td>\n",
       "      <td>40.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>title</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>RF</td>\n",
       "      <td>81.07</td>\n",
       "      <td>70.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>title</td>\n",
       "      <td>TFIDF Vectorizer</td>\n",
       "      <td>LR</td>\n",
       "      <td>91.47</td>\n",
       "      <td>72.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>title</td>\n",
       "      <td>TFIDF Vectorizer</td>\n",
       "      <td>SVC</td>\n",
       "      <td>13.60</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>title</td>\n",
       "      <td>TFIDF Vectorizer</td>\n",
       "      <td>RF</td>\n",
       "      <td>76.27</td>\n",
       "      <td>71.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>URL</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>LR</td>\n",
       "      <td>65.87</td>\n",
       "      <td>50.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>URL</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>SVC</td>\n",
       "      <td>44.40</td>\n",
       "      <td>38.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>URL</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>RF</td>\n",
       "      <td>69.73</td>\n",
       "      <td>55.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>URL</td>\n",
       "      <td>TFIDF Vectorizer</td>\n",
       "      <td>LR</td>\n",
       "      <td>88.13</td>\n",
       "      <td>53.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>URL</td>\n",
       "      <td>TFIDF Vectorizer</td>\n",
       "      <td>SVC</td>\n",
       "      <td>12.80</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>URL</td>\n",
       "      <td>TFIDF Vectorizer</td>\n",
       "      <td>RF</td>\n",
       "      <td>61.47</td>\n",
       "      <td>51.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>body + comments</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>LR</td>\n",
       "      <td>55.33</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>body + comments</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>SVC</td>\n",
       "      <td>47.07</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>body + comments</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>RF</td>\n",
       "      <td>80.27</td>\n",
       "      <td>45.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>body + comments</td>\n",
       "      <td>TFIDF Vectorizer</td>\n",
       "      <td>LR</td>\n",
       "      <td>75.73</td>\n",
       "      <td>38.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>body + comments</td>\n",
       "      <td>TFIDF Vectorizer</td>\n",
       "      <td>SVC</td>\n",
       "      <td>14.13</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>body + comments</td>\n",
       "      <td>TFIDF Vectorizer</td>\n",
       "      <td>RF</td>\n",
       "      <td>77.33</td>\n",
       "      <td>34.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>All Params</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>LR</td>\n",
       "      <td>68.53</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>All Params</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>SVC</td>\n",
       "      <td>77.33</td>\n",
       "      <td>46.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>All Params</td>\n",
       "      <td>Count Vectorizer</td>\n",
       "      <td>RF</td>\n",
       "      <td>95.73</td>\n",
       "      <td>82.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>All Params</td>\n",
       "      <td>TFIDF Vectorizer</td>\n",
       "      <td>LR</td>\n",
       "      <td>90.40</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>All Params</td>\n",
       "      <td>TFIDF Vectorizer</td>\n",
       "      <td>SVC</td>\n",
       "      <td>13.47</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>All Params</td>\n",
       "      <td>TFIDF Vectorizer</td>\n",
       "      <td>RF</td>\n",
       "      <td>92.00</td>\n",
       "      <td>72.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Considering        Vectorizer Model  Train Accuracy  Test Accuracy\n",
       "0              body  Count Vectorizer    LR           49.20           23.2\n",
       "1              body  Count Vectorizer   SVC           39.07           23.6\n",
       "2              body  Count Vectorizer    RF           62.53           43.6\n",
       "3              body  TFIDF Vectorizer    LR           52.00           32.4\n",
       "4              body  TFIDF Vectorizer   SVC           15.47           16.8\n",
       "5              body  TFIDF Vectorizer    RF           60.80           32.8\n",
       "6          comments  Count Vectorizer    LR           52.00           14.8\n",
       "7          comments  Count Vectorizer   SVC           20.40           12.4\n",
       "8          comments  Count Vectorizer    RF           62.00           18.0\n",
       "9          comments  TFIDF Vectorizer    LR           68.27           16.4\n",
       "10         comments  TFIDF Vectorizer   SVC           11.87           10.8\n",
       "11         comments  TFIDF Vectorizer    RF           52.40           16.0\n",
       "12            title  Count Vectorizer    LR           83.47           69.6\n",
       "13            title  Count Vectorizer   SVC           46.27           40.8\n",
       "14            title  Count Vectorizer    RF           81.07           70.4\n",
       "15            title  TFIDF Vectorizer    LR           91.47           72.4\n",
       "16            title  TFIDF Vectorizer   SVC           13.60           12.4\n",
       "17            title  TFIDF Vectorizer    RF           76.27           71.2\n",
       "18              URL  Count Vectorizer    LR           65.87           50.8\n",
       "19              URL  Count Vectorizer   SVC           44.40           38.8\n",
       "20              URL  Count Vectorizer    RF           69.73           55.6\n",
       "21              URL  TFIDF Vectorizer    LR           88.13           53.6\n",
       "22              URL  TFIDF Vectorizer   SVC           12.80           12.4\n",
       "23              URL  TFIDF Vectorizer    RF           61.47           51.6\n",
       "24  body + comments  Count Vectorizer    LR           55.33           25.2\n",
       "25  body + comments  Count Vectorizer   SVC           47.07           24.0\n",
       "26  body + comments  Count Vectorizer    RF           80.27           45.6\n",
       "27  body + comments  TFIDF Vectorizer    LR           75.73           38.4\n",
       "28  body + comments  TFIDF Vectorizer   SVC           14.13           13.6\n",
       "29  body + comments  TFIDF Vectorizer    RF           77.33           34.4\n",
       "30       All Params  Count Vectorizer    LR           68.53           42.0\n",
       "31       All Params  Count Vectorizer   SVC           77.33           46.8\n",
       "32       All Params  Count Vectorizer    RF           95.73           82.8\n",
       "33       All Params  TFIDF Vectorizer    LR           90.40           70.0\n",
       "34       All Params  TFIDF Vectorizer   SVC           13.47           12.8\n",
       "35       All Params  TFIDF Vectorizer    RF           92.00           72.8"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_dataframe = pd.DataFrame.from_records(accuracy_sheet)\n",
    "\n",
    "accuracy_dataframe.columns = ['Considering',\n",
    "                              'Vectorizer',\n",
    "                              'Model',\n",
    "                              'Train Accuracy',\n",
    "                              'Test Accuracy'\n",
    "                             ]\n",
    "\n",
    "accuracy_dataframe[\"Train Accuracy\"] = round(accuracy_dataframe[\"Train Accuracy\"]*100,2)\n",
    "accuracy_dataframe[\"Test Accuracy\"] = round(accuracy_dataframe[\"Test Accuracy\"]*100,2)\n",
    "\n",
    "accuracy_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT THE ACCURACY STATISTICS\n",
    "accuracy_dataframe.to_csv(\"../data/accuracy_stats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### We see that the following models perform the best:\n",
    "\n",
    "1. title + CV + LR \n",
    "2. title + CV + RF\n",
    "3. title + TFIDF + LR\n",
    "4. all params + CV + RF **(highest)**\n",
    "5. all params + TFIDF + LR\n",
    "6. all params + TFIDF + RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hence, we export the model with highest accuracy, i.e. Model 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvec_RF_model_export(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify = y)\n",
    "    # Creating the pipeline\n",
    "\n",
    "    cvec_rf_pipe = Pipeline([(\"cvec\", CountVectorizer()), \n",
    "                             (\"rf\", RandomForestClassifier(random_state = 42))])\n",
    "\n",
    "    # Setting hyperparameters\n",
    "    cvec_pipe_params = {\"cvec__max_features\"   : [1000], \n",
    "                        \"cvec__ngram_range\"    : [(1,1)], \n",
    "                        \"cvec__stop_words\"     : [None],\n",
    "                        \"rf__n_estimators\"     : [72],\n",
    "                        \"rf__min_samples_split\": [6],\n",
    "                        \"rf__min_samples_leaf\" : [2],\n",
    "                        \"rf__max_depth\"        : [20]}\n",
    "\n",
    "    # grid search\n",
    "    cvec_rf_gs = GridSearchCV(cvec_rf_pipe, \n",
    "                              param_grid = cvec_pipe_params, \n",
    "                              cv         = 5,\n",
    "                              n_jobs     = 6)\n",
    "\n",
    "    # Fitting the model to the training data\n",
    "    cvec_rf_gs.fit(X_train, y_train);\n",
    "\n",
    "    # Generating training predictions\n",
    "    cvec_rf_train_preds = cvec_rf_gs.predict(X_train)\n",
    "\n",
    "    # Generating test predictions\n",
    "    cvec_rf_preds       = cvec_rf_gs.predict(X_test) \n",
    "\n",
    "    # Generating test probabilities\n",
    "    cvec_rf_probas      = cvec_rf_gs.predict_proba(X_test)\n",
    "\n",
    "    # Creating the pipeline\n",
    "    cvec_rf_pipe = Pipeline([(\"cvec\", CountVectorizer()), \n",
    "                             (\"rf\", RandomForestClassifier(random_state = 42))])\n",
    "\n",
    "    # Setting CVEC and pipeline hyperparameters\n",
    "    cvec_pipe_params = {\"cvec__max_features\"   : [1000], \n",
    "                        \"cvec__ngram_range\"    : [(1,1)], \n",
    "                        \"cvec__stop_words\"     : [None],\n",
    "                        \"rf__n_estimators\"     : [72],\n",
    "                        \"rf__min_samples_split\": [6],\n",
    "                        \"rf__min_samples_leaf\" : [2],\n",
    "                        \"rf__max_depth\"        : [20]}\n",
    "\n",
    "    # Instantiating the grid search\n",
    "    cvec_rf_gs = GridSearchCV(cvec_rf_pipe, \n",
    "                              param_grid = cvec_pipe_params, \n",
    "                              cv         = 5,\n",
    "                              n_jobs     = 6)\n",
    "\n",
    "    # Fitting the model to the training data\n",
    "    cvec_rf_gs.fit(X_train, y_train);\n",
    "    \n",
    "    finalname = \"../models/CVRF_allParams.sav\"\n",
    "    pickle.dump(cvec_rf_gs, open(finalname, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy\n",
      "0.9573333333333334\n",
      "Test Accuracy\n",
      "0.828\n",
      "[[18  2  0  0  0  1  0  2  1  1]\n",
      " [ 1 23  0  0  0  0  0  0  0  1]\n",
      " [ 1  0 21  1  0  1  0  0  0  1]\n",
      " [ 0  2  0 23  0  0  0  0  0  0]\n",
      " [ 0  0  1  0 21  0  0  0  1  2]\n",
      " [ 0  3  0  0  0 20  0  0  0  2]\n",
      " [ 0  0  1  0  0  4 18  0  0  2]\n",
      " [ 2  0  2  0  0  0  2 17  0  2]\n",
      " [ 0  2  0  0  0  1  0  0 22  0]\n",
      " [ 0  0  0  0  0  1  0  0  0 24]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9573333333333334, 0.828)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec_RF(choice_X[\"All Params\"], df1[\"flair\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORTING MODEL\n",
    "cvec_RF_model_export(choice_X[\"All Params\"], df1[\"flair\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
